---
title: "Dating Experiment"
author: "Kalvin, Dan, and Jennifer"
date: "December 3, 2017"
output:
  word_document: default
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
library(knitr)#added by Kalvin to make tables
library(kableExtra)#added by Kalvin to make tables (having issues getting it to work)
library(lmtest)
library(sandwich)
library(multiwayvcov)
library(data.table)
library(foreign)
library(xtable)#added by Kalvin to make better tables
#library(stargazer)

knitr::opts_chunk$set(echo = TRUE)
```

```{r, include = FALSE}
#setwd("~/Berkeley/W241/Experiment/Final_Deliverables/final_paper_WIP")#Jen's personal comp
setwd("~/Personal/Grad SChool/Courses/w241/Experiment/") # w241_final_project/Final_Deliverables/final_paper_WIP") #Jen's work laptop
#setwd("C:/MIDS/W241/final_project/Final Paper")#Kalvin's working directory
```
## Abstract
The idea of self-presentation at the early stages of relationships has been well studied in human interactions and via electronic communications.  Our experiment continues this research on the impact of self-presentation of education attainment on online dating success on Tinder.  Our research found that ..

## Introduction

Since it's release in September 2012, Tinder has experienced a meteoric rise from TechCrunch's Crunchie Award for "Best New Startup of 2013" [^1] to being a world-wide dating application with over 50 million users.  As of April 2015, Tinder users swipe through 1.6 billion profiles and make more than 26 million matches per day.  The application is most popular with young adults with 83% of the user base being under the age of 35.  Despite the immense popularity of the platform, there are very few published studies regarding factors that impact Tinder match rate success.  Our research begins with a brief overview of the use of technology in dating and builds upon prior research regarding self-presentation in the early stages of relationships.  Specifically, we study the impact of education attainment on Tindermatch rate success.

[^1]:  https://techcrunch.com/video/tinder-wins-best-new-startup-of-2013-crunchies-awards-2013/518118930/


### Brief History of Online Dating

While many believe that online dating is a new phenomenon propelled by the launch of Match.com in 1995, the true conception of the idea goes back hundreds of years.  In fact, the first known use of a person using new communication tools to find love and companionship was in 1695 when a 30-year-old British bachelor placed a personal ad seeking "some good young gentlewoman with the fortune of 3,000 pounds or thereabouts."  The movement began with the upper echelons of society and moved to the general populous in the mid 1800s, however it was still viewed as deviant behavior.  The expansions of the American frontier further popularized personal ads, however, they became mainstream as lonely World War I soldiers sought female pen pals.

As technology advanced through the mid-twentieth century, dating services began to develop sophisticated methodology for connecting potential suitors.  In 1965, a group of Harvard students launched Operation Match, a $3 dating service in which users would submit paper questionnaires that would be processed on an IBM 1401 mainframe computer.  The computer matched the users to five potential matches and the results were returned by mail.  By the fall of 1965, the business had tens of thousands of users and offices throughout the country.

The 1980s brought about the rise of the VCR and the incredibly awkward era of video dating  Suitors would submit a personal video to dating services describing themselves and what they were seeking in a partner.  The service would then review the videos and manually match clients by common interest.

The 1990s saw the development of the Internet with the world's first website and server going live at CERN on December 20, 1990.  Within five years, there were 25 million internet users in the United States- that number grew to over 270 million users by 2015.  The combination of the new communications technology with the timeless human search for relationships led to the launch of Match.com in 1995.  The success of online dating was instantly obvious and in 2002, Wired Magazine prophetically stated, "Twenty years from now, the idea that someone looking for love won't look for it online will be silly, akin to skipping the card catalog to instead wander the stacks because the right books are found only by accident."  Since that article was written, more than 49 million Americans have tried online dating and approximately 17% of marriages in the last year were products of online dating.

### Prior Studies

Self-presentation and self-disclosure are well studied aspects of the relational development.  In Erving Goffman's 1959 study "Presentation of Self In Everyday Life", Goffman explores the way way in which individuals use strategic activities to "convey an impression to others which it is in his interest to convey."  These strategic activities are most important at the beginning of a relationship where an individual will "alter their self-presentational behavior in accordance with the values desired by the prospective date."  As Rowatt, Cunningham, & Druen noted, "men, but no women, chang[ed] their self-reported personality characteristics and physical appearance when they expected to meet a potential date.  Additionally, their propensity to exaggerate these characteristics was enhanced when the method of meeting was via email."  Dating success, however, is not solely tied to an exaggerated presentation of the ideal self.  Reis and Shaver's research indicated that the need to highlight one's positive attributes are experienced in tandem with the need to present' one's true self.  Interestingly, research by Gibbs, Ellison, and Heino indicates that 94% individuals disagreed that they had intentionally misrepresented themselves in their online communication and 87% felt that intentionally misrepresenting one's self to was unacceptable.  

Somewhat contradicting prior research, 2010 research by Hitsch, Hortaçsu, and Airely found no evidence for strategic behavior.  Their research found strong same-race preferences among users, which did not differ across age, income, or education levels.  The study, however, did show gender differences in mate preferences, specifically that women had stronger preference for income and men had stronger preference for physical attributes.

Our platform of interest, Tinder, has been the focus of a few published studies.  Gatter & Hodkinson found that "despite common stereotypes about those who use different types of online dating...no differences were found in motivations, suggesting that people may use both Online Dating Agencies and Tinder for similar reasons."  in specifying the motivations behind Tinder use, Sumter, Vandenbosch, and Ligtenberg found six motivating factors for use: Love, Casual Sex, Ease of Communication, Self-Worth Validation, Thrill of Excitement, and Trendiness.

## Research Question

## Hypothesis


$$ 
H_0: {\delta}M_{MD} = M_{BS}  = M_{PhD} = M_{NoEdu} \\
H_1: M_{MD} < M_{BS}  = M_{PhD} = M_{NoEdu} \\
H_2: M_{MD} +   M_{BS} \\
H_3: M_{BS} > M_{PhD} \\
H_4: 
$$
   

## Research Design (using ROXO grammar)
Our experiment created two fictitious online profiles that mimicked actual user profiles on Tinder.  The profiles were of a male and a female, each 29 years of age.  The profiles included five pictures of each individual in various settings, the individual's name, age, level of education attainment, and a comment stating, "Moving in couple of weeks and looking forward to meeting new people!"

The treatment classes are different levels of educational attainment.  Specifically, whether the individual is has earned a PhD, MD, or a Bachelor's Degree.  The control group displayed no educational attainment level in the profile.  

The 29 year old individual was selected as it is an age when an individual could plausibly have completed any of the treatment levels of education and it is an age where users were more likely to be looking for long-term relationships, rather than short-term flings.  

Based upon prior research, physical attributes tend to be highly significant in partner selection, especially for males, and therefore a single male and a single female were selected for the profile images in order to eliminate variation in match rate based upon aesthetics.  Further, the images used were the same images the individuals had used in their actual Tinder profiles to ensure validity of image selection.

The factitious profiles were displayed over a four week period in the eight largest cities in the United States: New York, Los Angeles, Chicago, Houston, Phoenix, Philadelphia, San Antonio, and San Diego (CITE ME).  It is important to note that neither individual whose pictures we used had previously used Tinder in any of the test cities, thus reducing the potential for any contamination or bias in the results.  Each profile-educational level combination was displayed to 100 users in each city for a one week period of time in November-December 2017.  Test subjects were randomly selected by  "swiping right" on every other profile displayed.  It should be noted that Tinder profile viewership was restricted to only those who were chosen as test subjects.  This eliminated the ability for a test subject to view the profile at multiple levels of education.  The only potential for spillover would be by an individual having multiple profiles and having been selected twice as a test subject or by recognizing the profile while viewing Tinder on another user's account.
  
After one week, we returned to the profile to collect data on which users also "swiped right" on our test profile.  This factorial design of two sexes, eight cities, and four education levels allowed for the analysis of different impacts of test conditions across sexes and locations.

Linearly, the design was: R - - 01, R X1 - 02, R X2 - 03, R X3 - 04


## Randomization engineering

Gathering a larger sample of profiles gave our analysis more power and confidence in the trends observed from the data. As the power calculations below demonstrate, if the study is conducted with individual suitor profiles as the measurement unit there would be a 95% probability of generating results that lead to the rejection of the null in the presence of a true treatment effect, an exceptionally high power. Alternatively, if the analysis considered the group level, then each city(8), each treatment(4) and each gender (2) would result in a much smaller n of 64 and the power in that experiment would be about 8%. The larger the sample size is the more robust the experiment is to identifying subtle differences in the data.


Taken from P93 in G&G
$$
\begin{aligned}
\beta = \Phi \Bigg(\bigg(\frac{|\mu_t -\mu_c| \sqrt{N}}{2\sigma}\bigg)- \Phi^{-1} \bigg(1- \frac{\alpha}{2}\bigg)\Bigg)\\
\end{aligned}
$$

Applying to our data:
```{r}
#Parameters
alpha = 0.05
mu_c = 100
mu_t = 102
sigma = 15

#calc final - individual level
n_1 = 3000
power_indiv = pnorm(((abs(mu_t-mu_c))*sqrt(n_1))/(2*sigma)-qnorm(1-(alpha/2)))
power_indiv
#calc final - city level (8 cities, M|F, 4 treatments)
n_2 = 8*2*4
power_city = pnorm(((abs(mu_t-mu_c))*sqrt(n_2))/(2*sigma)-qnorm(1-(alpha/2)))
power_city
```


<<WE SHOULD PROB CUT THIS>>As the results from the power test below indicate, the experiment requires five hundred forty two pariticipants should the delta between the mean for treatment and the mean for the control to vary by 10 and have a standard deviation of 50 matches(at the 95% confidence level). Our experiment compares the means across treatment and control, making it a two sided test. The hypothesis behind the experiment (that success is gender biased towards men) is a one sided test.

helpful reading (for Kalvin and Dan)
https://www.r-bloggers.com/design-of-experiments-%E2%80%93-power-calculations/

we could do an anova power test to compare across treatment levels, but I'm not sure how to do that
```{r}
power.t.test(delta = 10, sd = 50, power = 0.95, type = "two.sample",
  alternative = "one.sided")
```
The pilot demonstrated that mannually copying and pasting the details from each suitor's profile prohibited collecting a larger number of profiles. It took about three hours to gather four hundred profiles, meaning just over 2 minutes per profile. The use of automation was a very effective tool that enabled the collection of over five thousand suitor profiles in a four week period, which would have taken one hundred eight five hours by hand. Luckily, the website version of Tinder exactly matched the mobile phone version, greatly streamlining and standardizing the data collection approach. 

The research team wrote scripts in AutoHotKey (PC) and Maestro (the MAC equivalent) that control the operating system of the computer. The code would open up Tinder and navigate to developers' tools where the website's Javascript rendered soruce code (the HTML behind the webpage) was available. The source code listed the suitors name, age, a unique photo source path (very helpful for data validation later), and two details about the profile. After collecting and storing the source code in the appropriate folder that designated the city and treatment level, the code would automatically right swipe on the profile collect. 

Tinder restricts users from seeing repeat profiles to prevent communication between people who previously interacted unsuccessfully, making the trials independent. Each week a new randomly select batch of ladies and gentlemen were swiped on and put into the experiment. Any user of the Tinder application is subject to the behind the scences algorithm that serves up potential profiles; both the test male and female profiles, along with the profiles of the general Tinder user.

To further enhance the level of randomness within treatment assignment, every other profile was systematically rejected from the experiment. Given more time, the treatments could be delivered in alternative orders to help determine if the algorithm modifies the suitor population based on features of the profile. As the experiment was constrained to a five week window, the collection of covariate distributions augments the research team's understanding of the mechanisms driving tinder matches. For example, to help demonstrate the balance in treatment assignment, the distribution of suitor ages for each treatment condition are displayed in figures XX-XX below.

Figure XX (will add plots after they're finalized-- please check EDA google doc)

It is interesting to see that the age distribution has a right skew for all treatment conditions, and it is unclear that depending on Tinder to select suitors is truly random-- it could be the case that Tinder selects suitors based on the age set in the test profile, and it could also be the case that the general population of Tinder users is centered around the mid-20s age range.  But the consistency of this distribution across all conditions indicates that there was indeed an equal probability of receiving a given treatment condition, at least amongst the suitors selected by Tinder. 

The age distribution of suitors to the Male profile (female suitors) does seem to be centered approximately 2 years younger than that of suitors to the Female profile, and the skew appears to increase slightly with increasing education level.  However, statistical tests for the difference in average age by test condition yields a significant difference only between the male and female conditions (shown in figures XX-XX below), and its effect size is small-- approximately half a year.


## Experimental materials (e.g. treatment materials)
Objectively measuring individual's success in life is ambiguous and difficult, but a reasonably good proxy for research purposes could be educational attainment, job title prestige or educational institution prestige.  Below is a table of potential example degrees of severity for each of the proposed measures of success:

+-----------------------------------+---------------+-------------------------------------+
| Educational Attainment            |	Job Title     |	Educational Prestige (nearest)      |
+===================================+===============+=====================================+
| Advanced Degree (JD, PhD, MD, etc)|	Doctor      	| IVY (Harvard)                       |
+-----------------------------------+---------------+-------------------------------------+
| College Degree	                  | Teacher	      | State School (UMass)                |
+-----------------------------------+---------------+-------------------------------------+
| Associate Degree	                | Social Worker	| Community College (Bunker Hill CC)  |
+-----------------------------------+---------------+-------------------------------------+

As a team we considered the strengths and weakness of each respective success measure.  We planned on customizing the education institution to reflect broadly known schools in the vicinity of each city in the experiment. To enhance consistency of school selection across geography, Barron's Ranking list and the US News school ranking would have been consulted. However one of the drawbacks of educational prestige, that could not be remedies, is that educational prestige is most often determined while the individual is in their early twenties. At such a young age the future of any person is extremely malleable and fertility concerns are not particularly potent.  Generally it also takes time to become particularly skilled or develop expertise or to develop a positive reputation in a domain of interest. The research team leaned away from educational prestige as a success measure because it would not get close to measuring a potential tradeoff between prioritizing relationships and family in lieu of pursing other interests tied to XXX (quantifiable success ??) <<don't love this ending>>.

Professions then appeared as the better measure for success as individual's career paths are more fleshed out a few years later. Most adults know that doctors make significantly more than teachers who make more than social workers, however all three professions are in the business of helping people, and this could introduce potential bias. To elaborate on that point about bias, men might seek women with a nurturing profession (picturing the woman raising babies at home) and women might avoid men for fear of being replaced in the traditional household roles. Additionally Researchers at Microsoft recently published a paper demonstrating gender based job title bias in the general public's vernacular, implying that this success measure potentially introduces bias into an experiment (Bolukbasi, 2016).  Ultimately professions each carry their own reputation and predefined characteristics and controlling for that would be exceptionally difficult. Additionally, the novelty effect for women and men in unconventional roles also raised some concerns. Cross comparing average salary data from the Occupation Employment Statistics survey and the Current Population Survey reveal that top paying professions are male dominated. For example, the Bureau of Labor Statistics data shows that 66% of dentists, 64% of lawyers, and 73% of CEOs are men. Meaning that any high paying job selected would be more common among male profiles than female profiles making an apples to apples cross gender comparison questionable. For these reasons the final success measurement was not professions.

The government and society have created very clear breaks in educational attainment that are known to all, uniform across geographic lines, and would be easy to administer for an experiment. Generally people perceive access to education in the United States as exceptionally balanced across gender and bias concerns are mitigated. As the graph below indicates, on average there is a positive association between higher education and income levels, providing some validation for the positive life impact.  After deciding to run the experiment with educational attainment as the measure of success, the degrees of treatment were identified as MD, BS, and PhD. The research team was particularly interested in the difference between the impact of having a Medical Degree versus having a Research Degree. Both degrees require about five years to obtain, however there is significant difference in earnings potential. Due to concerns regarding the realness of the profile and limited time, the team decided not to test the impact of the associate's degree because other profiles on Tinder did not prominently display and associates degree. The control group would be a profile giving no information for the particular success measure. The treatments were delivered in the following non-monotonic order: MD, BS, no education, and PhD. 

In order to effectively deliver the treatment variable, showing the profile to a limited audience of potential suitors was paramount. To elaborate on that point, should a potential suitor see the profile change from "MD" to "BS" that would not only ruin the data point, but also risk the injured party flagging the account to the administrators and terminating the experiment prematurely. Fortunately, the premium Tinder account enabled the research team to control who had access to the profile so only the one hundred individuals in each city selected for that week's treatment were exposed; very effectively reducing potential spillover.



```{r, echo = FALSE}
degree = c("Secondary Education", "Associate's Degree","Bachelor's Degree","Master's Degree", "Research Doctorate","Doctor of Law", "MBA", "Doctor of Medicine" )
salary = c(51500,57100,79800,87700,94100,107000,118300,161200)

df_treatments = cbind(degree,salary)

barplot(as.numeric(df_treatments[,"salary"]), main="Salary by Education Level", xlab="Education", ylab="Salary ($)", names.arg=df_treatments[,"degree"])
```

The potential suitors were shown a profile that either read: "MD", "PhD", "BS" or the field to provide education information was left blank. A sample profile can be seen below.

```{r, echo = FALSE}
library(png)
library(grid)
img <- readPNG("sample_profile.png")
grid.raster(img)
```


## Measurement of variables
As discussed previously, the treatment in this experiment is the test profile's exposure of a given education level to a potential suitor, and the outcome is whether or not the suitor matches with the test profile.  When applying an education level treatment to the test profile, the measured test subject covariates include its age, sex, and location, and the measured suitor covariates include age, sex, whether or not school information is provided, whether or not job information is provided, and whether or not instagram photos are provided (and their count, if so).  These variables are described in table \textbf{XX} below.

```{r, echo = FALSE}
#(kalvin) i tried to use kable and kableExtra to format the table, but i'm having trouble using kableExtra
#(kalvin) i might try a different package later

column_names <- c("Variable", "Variable Type", "Source", "Description / Possible Values")
variables <- c("test profile education level", "suitor profile match", "test profile sex", 
               "test profile location", "suitor age", "suitor school***", "suitor job***", 
               "suitor instagram***", "number of instagram photos***")
variable_type <- c("treatment", "outcome", "covariate", "covariate", "covariate", 
                   "covariate", "covariate", "covariate", "covariate")
source <- c("test profile", "Tinder application", "test profile", "test profile", 
            "suitor source code", "suitor source code", "suitor source code", 
            "suitor source code", "suitor source code")
description <- c("4 possible values*: No education listed (control), Bachelor's, MD, PhD", 
                 "2 possible values: match or no match", 
                 "2 possible values: female or male", 
                 "8 possible values: Chicago, Houston, Los Angeles, New York, Philadelphia, Phoenix, San Antonio, San Diego", 
                 "Due to the filters set in the test profiles, this variable can range from 24 - 34 years.", 
                 "2 possible values: school information was detected or not", 
                 "2 possible values: job information was detected or not", 
                 "2 possible values: suitor profile included an instagram link or not", 
                 "if a suitor profile contained a link to an instagram account, this variable is the number of photos in the account")
variables_table <- matrix(c(variables, variable_type, source, description), nrow=length(variables))
#variables_table.app <- cbind(variables_table, source)
colnames(variables_table) <- column_names
#kable(variables_table, rownames=FALSE, padding=4)
#kable(variables_table, fontsize = 8, escape=FALSE, format.args=c(width=2), booktabs=TRUE)
kable(variables_table, fontsize = 6, caption="Table XX: Description of Variables") %>%
  kable_styling(bootstrap_options = c("striped","responsive"), full_width = FALSE)
  #kable_styling(bootstrap_options = c("striped","responsive")) %>%
  #column_spec(4, width="10em")
```
\* The initial experimental plan also included the 'Associates' education level as a treatment condition, however, technical issues at the start of the experiment prevented proper execution of the 'PhD' education level treatment, so the 'PhD' education level treatment was repeated and the 'Associates' education level treatment was skipped.

\** The test profile age was an originally planned covariate, but due to time constraints, only one age was used for the entire experiment.

\*** These variables are believed to be only partially observed-- see Section \textbf{XX} for further details.


_Issues with Measurement of Outcome_

After swiping right on a suitor, the Tinder application only provides notification if that suitor likes the test profile in return, and does not provide an indication of whether or not a suitor actually saw the profile or if the suitor disliked the test profile.  Our experiment therefore contains some rate of non-compliance and we are unfortunately unable to determine the compliance rate-- our estimated average treatment effect is thus the effect of the intent to treat.


_Issues with Measurement of Covariates_

The structure of the relevant source code in the Tinder browser interface is such that it contains a link to a suitor's profile image (which we use as a unique identifier for that suitor), the suitor's name, the suitor's age, and finally a maximum of two additional details that may include any combination of school information, job information, and instagram information.

It is known that a Tinder profile may display all three of these pieces of information, but none of the ## source codes collected contained more than two details.  It is highly unlikely that amongst the ## suitors encountered in the experiment, none displayed more than two of these details, so we believe that school information, job information, and instagram information are only partially observed, and without more in-depth examination of each suitor profile at the time of experiment execution, our analysis is unable to fully determine the education and job status/level, as well as instagram information, for each suitor.  Due to time constraints, thorough examination of each profile was unfortunately not an option-- we were required to use an automated swiping method which acquired covariate information from source code.  It is also known that a Tinder profile may additionally display the suitor's distance and favorite spotify songs, but none of this information was present in the suitor source codes acquired during the experiment, and these two covariates were thus unobserved.

The source code indicates which suitor details are the profile image, the name, and the age, but does not indicate which details are school, job, or instagram information.  Our data collection process searches the text of these details to make a best guess as to what type of detail it is (instagram information is easily identified, but not school or job information).  So for some of the school and job details that were collected, it could not be determined whether the detail represented education or employment.


_Data Pre-processing_
Since the non-binary variables are categorical, they were binarized using indicator variables for each category...


## Modeling choices
calculation of statistical power

## Experiment Results
In text description of your results
Figures and tables that support your in text description
Clean, clear, well articulated relationships between your theory, your hypotheses, the numbers that your models produce, and the figures you present

```{r, echo = FALSE}
setwd("~/Personal/Grad SChool/Courses/w241/Experiment")
df = read.csv("Dating_experiment-Final_Project_DataFV.csv")
head(df)
```


```{r}
#removing missing values
#for(i in 1:ncol(df)){
#  x = df[,i]
#  if(is.character(df[,i])){
#    df[,i][is.na(x) | nchar(x) == 0] = 'not available'
#  } else if(is.numeric(df[,i])){
#    df[,i][is.na(x)] = 0.0001  # didn't want too small of a number because of scaling function later
#  }
#}
```


### Exporatory Data Analysis 

From Kavlin
```{r}
robustSEs <- function(my.model){
  my.model$vcovHC <- vcovHC(my.model)
  my.model.summary <- coeftest(my.model, my.model$vcovHC)
  return(my.model.summary)
}
```

The randomization of our treatment assignment was dependent on Tinder's selection of suitors.  Since Tinder's algorithm for this selection is unknown and potentially complex, balance across the available covariates was examined to ensure that the experiment yields an apples-to-apples comparison.

```{r echo=FALSE, message=FALSE}
df$age_indicator <- 1.0*(!is.na(df$age))
df$ig_indicator <- 1.0*(!is.na(df$num_ig))
```

### Missing Instagram Information

Like school and job information, instagram information was missing from many of our suitor profiles.  However, it was easily detected when present in the source code since the format for an instagram detail was consistent across suitor profiles (of the form "X Instagram Photos").  One technical detail of the structure of suitor source codes is that school and job information took priority-- an instagram detail is only present when less than two school or job details are present.  Therefore, whether or not a profile's source code contains an instagram detail could be used to represent the amount of information a suitor chose to include in his or her profile-- the missingness of instagram details is thus checked for balance across experimental conditions.  Table XXX below shows the count of profiles with instagram information detected between the male and female test profiles.

```{r results="asis", echo=FALSE, message=FALSE}
missing.ig.female <- 100*(1-mean(df$ig_indicator[df$female==1]))
missing.ig.male <- 100*(1-mean(df$ig_indicator[df$female==0]))
#table(df[,c('female','ig_indicator')])
total.female <- sum(df$female==1)
total.male <- sum(df$female==0)
num.ig.female <- sum(df$ig_indicator[df$female==1])
num.ig.male <- sum(df$ig_indicator[df$female==0])

column.names <- c("Gender", "Total Profiles", "Profiles with Instagram", "% Missing Instagram Info")
column.1 <- c("Female", "Male")
column.2 <- c(total.female, total.male)
column.3 <- c(num.ig.female, num.ig.male)
column.4 <- c(missing.ig.female, missing.ig.male)
missing.ig.table <- matrix(c(column.1, column.2, column.3, column.4), nrow=length(column.1))
colnames(missing.ig.table) <- column.names
print(xtable(missing.ig.table, digits=c(0,0,2,2,2)), type="latex")#setting decimal places doesn't seem to be working
```

```{r echo=FALSE, message=FALSE}
ig.gender <- lm(ig_indicator ~ female, data=df)
ig.gender.summary <- robustSEs(ig.gender)
ig.gender.SEs <- c(ig.gender.summary[3], ig.gender.summary[4])
```

Table XXX below shows the count of profiles with instagram information detected between all treatment conditions.

```{r results="asis", echo=FALSE, message=FALSE}
missing.ig.noedu <- 100*(1-mean(df$ig_indicator[df$noedu==1]))
missing.ig.bs <- 100*(1-mean(df$ig_indicator[df$bs==1]))
missing.ig.md <- 100*(1-mean(df$ig_indicator[df$md==1]))
missing.ig.phd <- 100*(1-mean(df$ig_indicator[df$phd==1]))
total.noedu <- sum(df$noedu==1)
total.bs <- sum(df$bs==1)
total.md <- sum(df$md==1)
total.phd <- sum(df$phd==1)
num.ig.noedu <- sum(df$ig_indicator[df$noedu==1])
num.ig.bs <- sum(df$ig_indicator[df$bs==1])
num.ig.md <- sum(df$ig_indicator[df$md==1])
num.ig.phd <- sum(df$ig_indicator[df$phd==1])

column.names <- c("Education Level", "Total Profiles", "Profiles with Instagram", "% Missing Instagram Info")
column.1 <- c("No Education", "BS", "MD", "PhD")
column.2 <- c(total.noedu, total.bs, total.md, total.phd)
column.3 <- c(num.ig.noedu, num.ig.bs, num.ig.md, num.ig.phd)
column.4 <- c(missing.ig.noedu, missing.ig.bs, missing.ig.md, missing.ig.phd)
missing.ig.table <- matrix(c(column.1, column.2, column.3, column.4), nrow=length(column.1))
colnames(missing.ig.table) <- column.names
print(xtable(missing.ig.table, digits=c(0,0,2,2,2)), type="latex")#setting decimal places doesn't seem to be working
```

```{r echo=FALSE, message=FALSE}
ig.treatment <- lm(ig_indicator ~ bs + md + phd, data=df)
ig.treatment.summary <- robustSEs(ig.treatment)
ig.treatment.SEs <- c(ig.treatment.summary[5], ig.treatment.summary[6], ig.treatment.summary[7], ig.treatment.summary[8])
```

Table XXX below shows the count of profiles with instagram information detected between all testing locations.

```{r results="asis", echo=FALSE, message=FALSE}
missing.ig.chicago <- 100*(1-mean(df$ig_indicator[df$chicago==1]))
missing.ig.houston <- 100*(1-mean(df$ig_indicator[df$houston==1]))
missing.ig.losangeles <- 100*(1-mean(df$ig_indicator[df$losangeles==1]))
missing.ig.newyork <- 100*(1-mean(df$ig_indicator[df$newyork==1]))
missing.ig.philadelphia <- 100*(1-mean(df$ig_indicator[df$philadelphia==1]))
missing.ig.phoenix <- 100*(1-mean(df$ig_indicator[df$phoenix==1]))
missing.ig.sanantonio <- 100*(1-mean(df$ig_indicator[df$sanantonio==1]))
missing.ig.sandiego <- 100*(1-mean(df$ig_indicator[df$sandiego==1]))
total.chicago <- sum(df$chicago==1)
total.houston <- sum(df$houston==1)
total.losangeles <- sum(df$losangeles==1)
total.newyork <- sum(df$newyork==1)
total.philadelphia <- sum(df$philadelphia==1)
total.phoenix <- sum(df$phoenix==1)
total.sanantonio <- sum(df$sanantonio==1)
total.sandiego <- sum(df$sandiego==1)
num.ig.chicago <- sum(df$ig_indicator[df$chicago==1])
num.ig.houston <- sum(df$ig_indicator[df$houston==1])
num.ig.losangeles <- sum(df$ig_indicator[df$losangeles==1])
num.ig.newyork <- sum(df$ig_indicator[df$newyork==1])
num.ig.philadelphia <- sum(df$ig_indicator[df$philadelphia==1])
num.ig.phoenix <- sum(df$ig_indicator[df$phoenix==1])
num.ig.sanantonio <- sum(df$ig_indicator[df$sanantonio==1])
num.ig.sandiego <- sum(df$ig_indicator[df$sandiego==1])

column.names <- c("City", "Total Profiles", "Profiles with Instagram", "% Missing Instagram Info")
column.1 <- c("Chicago", "Houston", "Los Angeles", "New York", "Phildelphia", "Phoenix", "San Antonio", "San Diego")
column.2 <- c(total.chicago, total.houston, total.losangeles, total.newyork, 
              total.philadelphia, total.phoenix, total.sanantonio, total.sandiego)
column.3 <- c(num.ig.chicago, num.ig.houston, num.ig.losangeles, num.ig.newyork, 
              num.ig.philadelphia, num.ig.phoenix, num.ig.sanantonio, num.ig.sandiego)
column.4 <- c(missing.ig.chicago, missing.ig.houston, missing.ig.losangeles, missing.ig.newyork, 
              missing.ig.philadelphia, missing.ig.phoenix, missing.ig.sanantonio, missing.ig.sandiego)

missing.ig.table <- matrix(c(column.1, column.2, column.3, column.4), nrow=length(column.1))
colnames(missing.ig.table) <- column.names
print(xtable(missing.ig.table, digits=c(0,0,2,2,2)), type="latex")#setting decimal places doesn't seem to be working
```

```{r echo=FALSE, message=FALSE}
ig.city <- lm(ig_indicator ~ houston + losangeles + newyork + philadelphia + phoenix + sanantonio + sandiego, data=df)
ig.city.summary <- robustSEs(ig.city)
ig.city.SEs <- c(ig.city.summary[9], ig.city.summary[10], ig.city.summary[11], ig.city.summary[12], ig.city.summary[13], ig.city.summary[14], ig.city.summary[15], ig.city.summary[16])
```

Table XXX below shows the results of the tests for a difference in average missingness of instagram information, by gender, treatment condition, and location.  While some differences are statistically significant, we do not consider them practically significant, and the missingess of instagram information thus passes the balance check.

```{r results="asis", echo=FALSE, message=FALSE}
stargazer(ig.gender.summary, ig.treatment.summary,ig.city.summary, se=list(ig.gender.SEs, ig.treatment.SEs, ig.city.SEs), type = "latex", report = "vcs*", single.row = T, column.labels = c("Gender","Treatment", "Location"), title ="Comparison of IG Missingness")
#cat("\n\n\\pagebreak\n")
```

### Missing Age Values

Table XXX below shows the count of profiles that contain the suitor's age, between males and females.

```{r results="asis", echo=FALSE, message=FALSE}
missing.age.female <- 100*(1-mean(df$age_indicator[df$female==1]))
missing.age.male <- 100*(1-mean(df$age_indicator[df$female==0]))

total.female <- sum(df$female==1)
total.male <- sum(df$female==0)
num.age.female <- sum(df$age_indicator[df$female==1])
num.age.male <- sum(df$age_indicator[df$female==0])

column.names <- c("Gender", "Total Profiles", "Profiles with Age", "% Missing Age")
column.1 <- c("Female", "Male")
column.2 <- c(total.female, total.male)
column.3 <- c(num.age.female, num.age.male)
column.4 <- c(missing.age.female, missing.age.male)
missing.age.table <- matrix(c(column.1, column.2, column.3, column.4), nrow=length(column.1))
colnames(missing.age.table) <- column.names
print(xtable(missing.age.table, digits=c(0,0,2,2,2)), type="latex")#setting decimal places doesn't seem to be working
```

```{r echo=FALSE, message=FALSE}
age.gender <- lm(age_indicator ~ female, data=df)
age.gender.summary <- robustSEs(age.gender)
age.gender.SEs <- c(age.gender.summary[3], age.gender.summary[4])
```

Table XXX below shows the count of profiles that contain the suitor's age, between all treatment conditions.

```{r results="asis", echo=FALSE, message=FALSE}
missing.age.noedu <- 100*(1-mean(df$age_indicator[df$noedu==1]))
missing.age.bs <- 100*(1-mean(df$age_indicator[df$bs==1]))
missing.age.md <- 100*(1-mean(df$age_indicator[df$md==1]))
missing.age.phd <- 100*(1-mean(df$age_indicator[df$phd==1]))
total.noedu <- sum(df$noedu==1)
total.bs <- sum(df$bs==1)
total.md <- sum(df$md==1)
total.phd <- sum(df$phd==1)
num.age.noedu <- sum(df$age_indicator[df$noedu==1])
num.age.bs <- sum(df$age_indicator[df$bs==1])
num.age.md <- sum(df$age_indicator[df$md==1])
num.age.phd <- sum(df$age_indicator[df$phd==1])

column.names <- c("Education Level", "Total Profiles", "Profiles with Age", "% Missing Age")
column.1 <- c("No Education", "BS", "MD", "PhD")
column.2 <- c(total.noedu, total.bs, total.md, total.phd)
column.3 <- c(num.age.noedu, num.age.bs, num.age.md, num.age.phd)
column.4 <- c(missing.age.noedu, missing.age.bs, missing.age.md, missing.age.phd)
missing.age.table <- matrix(c(column.1, column.2, column.3, column.4), nrow=length(column.1))
colnames(missing.age.table) <- column.names
print(xtable(missing.age.table, digits=c(0,0,2,2,2)), type="latex")#setting decimal places doesn't seem to be working
```

```{r echo=FALSE, message=FALSE}
age.treatment <- lm(age_indicator ~ bs + md + phd, data=df)
age.treatment.summary <- robustSEs(age.treatment)
age.treatment.SEs <- c(age.treatment.summary[5], age.treatment.summary[6], age.treatment.summary[7], age.treatment.summary[8])
```

Table XXX below shows the count of profiles that contain the suitor's age, between all testing locations.

```{r results="asis", echo=FALSE, message=FALSE}
missing.age.chicago <- 100*(1-mean(df$age_indicator[df$chicago==1]))
missing.age.houston <- 100*(1-mean(df$age_indicator[df$houston==1]))
missing.age.losangeles <- 100*(1-mean(df$age_indicator[df$losangeles==1]))
missing.age.newyork <- 100*(1-mean(df$age_indicator[df$newyork==1]))
missing.age.philadelphia <- 100*(1-mean(df$age_indicator[df$philadelphia==1]))
missing.age.phoenix <- 100*(1-mean(df$age_indicator[df$phoenix==1]))
missing.age.sanantonio <- 100*(1-mean(df$age_indicator[df$sanantonio==1]))
missing.age.sandiego <- 100*(1-mean(df$age_indicator[df$sandiego==1]))
total.chicago <- sum(df$chicago==1)
total.houston <- sum(df$houston==1)
total.losangeles <- sum(df$losangeles==1)
total.newyork <- sum(df$newyork==1)
total.philadelphia <- sum(df$philadelphia==1)
total.phoenix <- sum(df$phoenix==1)
total.sanantonio <- sum(df$sanantonio==1)
total.sandiego <- sum(df$sandiego==1)
num.age.chicago <- sum(df$age_indicator[df$chicago==1])
num.age.houston <- sum(df$age_indicator[df$houston==1])
num.age.losangeles <- sum(df$age_indicator[df$losangeles==1])
num.age.newyork <- sum(df$age_indicator[df$newyork==1])
num.age.philadelphia <- sum(df$age_indicator[df$philadelphia==1])
num.age.phoenix <- sum(df$age_indicator[df$phoenix==1])
num.age.sanantonio <- sum(df$age_indicator[df$sanantonio==1])
num.age.sandiego <- sum(df$age_indicator[df$sandiego==1])

column.names <- c("City", "Total Profiles", "Profiles with Age", "% Missing Age")
column.1 <- c("Chicago", "Houston", "Los Angeles", "New York", "Phildelphia", "Phoenix", "San Antonio", "San Diego")
column.2 <- c(total.chicago, total.houston, total.losangeles, total.newyork, 
              total.philadelphia, total.phoenix, total.sanantonio, total.sandiego)
column.3 <- c(num.age.chicago, num.age.houston, num.age.losangeles, num.age.newyork, 
              num.age.philadelphia, num.age.phoenix, num.age.sanantonio, num.age.sandiego)
column.4 <- c(missing.age.chicago, missing.age.houston, missing.age.losangeles, missing.age.newyork, 
              missing.age.philadelphia, missing.age.phoenix, missing.age.sanantonio, missing.age.sandiego)

missing.age.table <- matrix(c(column.1, column.2, column.3, column.4), nrow=length(column.1))
colnames(missing.age.table) <- column.names
print(xtable(missing.age.table, digits=c(0,0,2,2,2)), type="latex")#setting decimal places doesn't seem to be working
```

```{r echo=FALSE, message=FALSE}
age.city <- lm(age_indicator ~ houston + losangeles + newyork + philadelphia + phoenix + sanantonio + sandiego, data=df)
age.city.summary <- robustSEs(age.city)
age.city.SEs <- c(age.city.summary[9], age.city.summary[10], age.city.summary[11], age.city.summary[12], age.city.summary[13], age.city.summary[14], age.city.summary[15], age.city.summary[16])
```

Table XXX below shows the results of the tests for a difference in average missingness of the suitor's age, by gender, treatment condition, and location.  While some differences are statistically significant (between males and females, for example), we do not consider them practically significant, and the missingess of age information thus passes the balance check.

```{r results="asis", echo=FALSE, message=FALSE}
stargazer(age.gender.summary, age.treatment.summary,age.city.summary, se=list(age.gender.SEs, age.treatment.SEs, age.city.SEs), type = "latex", report = "vcs*", single.row = T, column.labels = c("Gender","Treatment", "Location"), title ="Comparison of Age Missingness")
#cat("\n\n\\pagebreak\n")
```

### EDA: Age Distribution

In addition to the missingness of covariates, the age distribution of suitors was also checked for balance across our treatment conditions.  The test profiles had set an age filter of 24-34, and the suitor ages were expected to be evenly distributed in this range.  However in every test condition and for every covariate, the suitors sampled had an age distribution that was centered near 24-25, with a strong right skew.  Figure XXX below shows the ages of suitors in each treatment condition-no education shown, bachelor's degree, MD, and PhD.

```{r echo=FALSE, message=FALSE}
#turn into subplots
hist(df$age[df$noedu==1])
hist(df$age[df$bs==1])
hist(df$age[df$md==1])
hist(df$age[df$phd==1])
```
 
The strong skew in suitor age distribution raised a few questions about the use of Tinder to randomize treatment assignment-- for example, does Tinder select suitors based on a profile's age or its age filter, or is it the case that the general population of Tinder users is around 25 years old?  Figures XXX-XXX below show the ages of suitors for the other experimental conditions.

```{r echo=FALSE, message=FALSE}
#turn into subplots
hist(df$age[df$female==1])
hist(df$age[df$female==0])
```


```{r echo=FALSE, message=FALSE}
#turn into subplots
hist(df$age[df$chicago==1])
hist(df$age[df$houston==1])
hist(df$age[df$losangeles==1])
hist(df$age[df$newyork==1])
hist(df$age[df$philadelphia==1])
hist(df$age[df$phoenix==1])
hist(df$age[df$sanantonio==1])
hist(df$age[df$sandiego==1])
```

Fortunately, as shown in Figures XXX-XXX above, the skew in age distribution is very similar for all covariate values.  Table XXX below shows the results of the tests for a difference in the average suitor age, by gender, treatment condition, and location.  There appears to be a significant result that the male profile was shown suitors who were on average 0.59 years younger than those shown to the female profile, but for this experiment, a half-year is considered a small effect size.  Most importantly, no significant difference in average suitor age was found between treatments, so the experiment still yields an apples-to-apples comparison.

```{r echo=FALSE, message=FALSE}
agemodel.gender <- lm(age ~ female, data=df)
agemodel.gender.summary <- robustSEs(agemodel.gender)
agemodel.gender.SEs <- c(agemodel.gender.summary[3], agemodel.gender.summary[4])
```

```{r echo=FALSE, message=FALSE}
agemodel.treatment <- lm(age ~ bs + md + phd, data=df)
agemodel.treatment.summary <- robustSEs(agemodel.treatment)
agemodel.treatment.SEs <- c(agemodel.gender.summary[5], agemodel.gender.summary[6], agemodel.gender.summary[7], agemodel.gender.summary[8])
```

```{r echo=FALSE, message=FALSE}
agemodel.city <- lm(age ~ houston + losangeles + newyork + philadelphia + phoenix + sanantonio + sandiego, data=df)
agemodel.city.summary <- robustSEs(agemodel.city)
agemodel.city.SEs <- c(agemodel.city.summary[9], agemodel.city.summary[10], agemodel.city.summary[11], agemodel.city.summary[12], agemodel.city.summary[13], agemodel.city.summary[14], agemodel.city.summary[15], agemodel.city.summary[16])
```

```{r results="asis", echo=FALSE, message=FALSE}
stargazer(agemodel.gender.summary, agemodel.treatment.summary,agemodel.city.summary, se=list(agemodel.gender.SEs, agemodel.treatment.SEs, agemodel.city.SEs), type = "latex", report = "vcs*", single.row = T, column.labels = c("Gender","Treatment", "Location"), title ="Comparison of Average Age")
#cat("\n\n\\pagebreak\n")
```

## Model Results
As a research team we were extremely excited to see any kind of results. In our pilot and in the first round of testing we struggled with a low overall match rate (0/400 swipes and 5/800) so we were unable to perform initial calculations to evaluate the treatment's effect. The primary concern was that the Tinder user made decisions based solely on physical attractiveness and there would be no variance across our treatment variable. It wasn't until week four of swiping that we could compare the numbers across treatments.  


High Level Overview of Outcomes
```{r, echo = FALSE}
cnts = table(df$matches, df$female, dnn=c("Matches","Female Indicator"))
addmargins(cnts)
```

```{r, echo = FALSE}
cnts_treat = table(df$matches,df$treatment, dnn=c("Matches", "Treatment"))
addmargins(cnts_treat)
```


Caclulating the ATE:
Control is in the intercept base the base (otherwise we would have problems with multicolinearity; same thing with including the male indicator)

## Models
$$ 
y_i = {\beta}_0 + {\beta}_1Z_i + e_i \\
Y_{Matches} = \beta_0 + \beta_1 MD + \beta_2 PhD + \beta_3 BS + \beta_4 female + \beta_5 female* MD + \beta_6 female*PhD  + \beta_7 female*BS  + e_i \\
$$

Test the hypothesis that the profile for our female is more effective, in terms of producing additional matches, than the male profile:
```{r, echo = FALSE}
model_gender = lm(matches ~ md + bs + phd  + female + female*md + female*bs + female*phd, data = df)
summary(model_gender)
#plot(model_MD_base, which = c(1:5))
```
^ compare with power test results 

After enhancing the profiles, we finally saw more matches come in and much to our surprise, the initial theory was completely unfounded. As the regression table shows, we regressed the number of matches against each of the treatments, the female indicator and we also tested for interactions between the treatment variables and gender.  If you look at the first number highlighted in yellow, you can see the highest level of education, MD, has a positive and significant ATE of 0.06 for the female account, meaning that the number of matches actually increased. Prior observational research from match.com indicated that income levels for females was not significant and we were surprised to see a different pattern.

Not surprisingly, with only 13 male matches and over 500 female matches the data results in a highly significant effect on the female indicator variable where the female match rate is 0.16 higher. We didn't want to draw too many conclusions from the male matched records because anything that we might conclude would just be p-hacking, in the regressions on the following page we removed all the male records for that reason and the sample size drops from n = 6,269 to n = 3,034. Additionally, the seventy nine suitor profiles without age information were also removed, but as discussed in the EDA section there is no bias introduced with this action.

The results from the prior page are included as the base model in column one, but the research team wanted to add additional covariates to the model little by little to fully understand their impact. The first variable we looked at was age, as the suitor profiles increase in age, there is a significant, but small decrease in the match rate of -0.005, highlighted in column 2.  In column 3 we consider the impact of location, but unlike in our baseline model, there isn't a control column for location that would be the obvious choice to leave out. The coefficients for location are compared to the values for Chicago. We saw significantly more matches in LA than any other city, and Chicago had slightly more matches than the remaining 5, as indicated by the negative coefficient (not all significant). In column 4 we consider the impact of the indicator for a suitor writing in a job title or school. The regression shows the additional covariates don't add bias. Finally in column 5 we have a comprehensive model that amalgamates all the covariates. The most important takeaway from these more detailed models is that the MD treatment is highly significant across in every instance.

```{r, fig.width =12, results='asis'}
library(stargazer)
#prep data
df_female = subset(df, df$female == 1)
#changes missing values to something easier to delete (done later)
df_female[,"age"][is.na(df_female[,"age"])] = 0.0001
df_female = subset(df_female, df_female$age != 0.0001)

#location model
model_location = lm(matches ~ md + bs + phd  + losangeles + houston + newyork + phoenix + sandiego +sanantonio +philadelphia, complete.cases(T), data = df_female)
#age
model_age = lm(matches ~ md + bs + phd  + age  , data = df_female)
#details
model_details = lm(matches ~ md + bs + phd  +  school + job, data = df_female)

#all
model_all = lm(matches ~ md + bs + phd  +  age + losangeles + houston + newyork + phoenix + sandiego +sanantonio +philadelphia +  school + job  , data = df_female, complete.cases(T))
#Change type to "latex" for knitting to pdf
stargazer(model_gender, model_ageInteraction, model_location, model_details, model_all,type = "text", report = "vcs*", single.row = T, column.labels = c("Base","Age", "Location", "Details", "All"), title ="Comparison of treatments")
#cat("\n\n\\pagebreak\n")
```


Test to see if models are statistically different and declare best one.
```{r}
anova(model_location, model_all)
```

Actual Power of the experiment:
```{r}
#Parameters
alpha = 0.05
mu_c = mean(df_female$matches[df_female$noedu==1])
mu_c
mu_t = mean((df_female$matches[df_female$md==1]),na.rm = T)
mu_t
sigma = sd((df_female$matches[df_female$md==1]),na.rm = T)

#calc final - individual level
n_1 = 3034
power_indiv = pnorm(((abs(mu_t-mu_c))*sqrt(n_1))/(2*sigma)-qnorm(1-(alpha/2)))
power_indiv
```
While the mean between the treatment and control were very small, the large sample size engenders a high powered experiment. 


\pagebreak
## Conclusion
High level statements about causality and discussion of next steps:

Tactical
Fully capture all available covariates in suitor profile
Run code from computers with the same operating system
Allow collection of matches over a longer duration
Test treatments in parallel
Include lower levels of educational attainment & JD/Masters

Strategic
Incorporate additional covariates such as profile age, swiping day|time, international testing for cultural impact, testing in rural/suburban locations
Increase number of test profiles and test for attractiveness and race
Run on different dating applications 
Test for generalizability with job title and educational prestige
Consider non heteronormative couples
Control for impact of distance swiping

Finally, we wanted to share our thoughts for potential improvements with more time and money. We have divided them into 2 main categories, tactical recommendations regarding the execution of the experiment and strategic recommendations regarding extensions of the experiment. For example, on the tactical side we saw additional matches came in after the collection period to mitigate that we could extend the collection period. A strategic extension would be to run the experiment on different dating applications to enable commenting on the macro courtship trends beyond just Tinder. Please feel free to check out the other ideas at your leisure, at this time we would like to thank you for your attention and open the floor up for questions and comments!

\pagebreak
## Works Consulted
