---
title: "Dating Experiment"
author: "Kalvin, Dan, and Jennifer"
date: "December 3, 2017"
output:
  #word_document: default
  pdf_document: default
  #html_document: default
---

```{r setup, include=FALSE}
library(knitr)#added by Kalvin to make tables
library(kableExtra)#added by Kalvin to make tables (having issues getting it to work)
library(lmtest)
library(sandwich)
library(multiwayvcov)
library(data.table)
library(foreign)
library(xtable)#added by Kalvin to make better tables
library(stargazer)
#added for treatment graphs
library(ggplot2)
library(stringr)
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include = FALSE}
#setwd("~/Berkeley/W241/Experiment/Final_Deliverables/final_paper_WIP")#Jen's personal comp
setwd("~/Personal/Grad SChool/Courses/w241/Experiment/") # w241_final_project/Final_Deliverables/final_paper_WIP") #Jen's work laptop
#setwd("C:/MIDS/W241/final_project/Final Paper")#Kalvin's working directory
#setwd("~/Desktop/w241_final_project/w241_final_project/Final_Deliverables/final_paper_WIP/")
```
## Abstract
The idea of self-presentation at the early stages of relationships has been well studied in the realms of human interactions and electronic communications.  Our experiment continues this research in this domain with a focus on the impact of self-presentation of education attainment on online dating success on Tinder.  Our research finds that despite anectdotal claims that females with higher education experienced greater difficulty in finding suitors, females presenting a medical degree on their Tinder profile experienced a 6% increase in match rates over those without any education listed.  Women who presented a PhD on their Tinder profile experienced no statistically significant impact in match rates.

## Introduction

Since its release in September 2012, Tinder has experienced a meteoric rise from TechCrunch's Crunchie Award for "Best New Startup of 2013" [^1] to becoming a world-wide dating application with over 50 million users.[^2]  As of April 2015, Tinder users swipe through 1.6 billion profiles and make more than 26 million matches per day.[^3]  The application is most popular with young adults with 83% of the user base being under the age of 35.[^4]  Despite the immense popularity of the platform, there are very few published studies regarding factors that impact Tinder match rate success.  Our research begins with a brief overview of the use of technology in dating and builds upon prior research regarding self-presentation in the early stages of relationships.  Specifically, we study the impact of education attainment on Tinder match rate success.

To achieve and contextualize the goal of our study, our paper begins with a brief history of online dating followed by a review of prior studies in this arena.  Our research design and data collection processes are discussed along with challenges associated with the aforementioned data collection on Tinder.  After our results are analyzed, we propose ways in which future studies may improve upon our results and add robustness to this field of research.

[^1]:  https://techcrunch.com/video/tinder-wins-best-new-startup-of-2013-crunchies-awards-2013/518118930/
[^2]:  https://en.wikipedia.org/wiki/Tinder_(app)
[^3]:  http://mashable.com/2015/04/15/coachella-tinder-usage-sky-rockets/#1PeiJxGLBmqU
[^4]:  http://www.businessinsider.com/a-lot-of-people-on-tinder-arent-actually-single-2015-5

### Brief History of Online Dating

While many believe that online dating is a new phenomenon propelled by the launch of Match.com in 1995, the true conception of the idea goes back hundreds of years.  In fact, the first known use of a person using new communication tools to find love and companionship was in 1695 when a 30-year-old British bachelor placed a personal ad seeking "some good young gentlewoman with the fortune of 3,000 pounds or thereabouts."[^5]  The movement began with the upper echelons of society and moved to the general populous in the mid 1800s, however it was still viewed as deviant behavior.[^6]  The expansions of the American frontier further popularized personal ads, however, they became mainstream as lonely World War I soldiers sought female pen pals.[^7]

[^5]:  https://www.huffingtonpost.com/susie-lee/timeline-online-dating-fr_b_9228040.html
[^6]:  Id.
[^7]:  Id.

As technology advanced through the mid-twentieth century, dating services began to develop sophisticated methodology for connecting potential suitors.  In 1965, a group of Harvard students launched Operation Match, a $3 dating service in which users would submit paper questionnaires that would be processed on an IBM 1401 mainframe computer.  The computer matched the users to five potential matches and the results were returned by mail.[^8]  By the fall of 1965, the business had tens of thousands of users and offices throughout the country.[^9]

The 1980s brought about the rise of the VCR and the incredibly awkward era of video dating.[^10]  Suitors would submit a personal video to dating services describing themselves and what they were seeking in a partner.  The service would then review the videos and manually match clients by common interest.[^11]

The 1990s saw the development of the Internet with the world's first website and server going live at CERN on December 20, 1990.[^12]  Within five years, there were 25 million internet users in the United States- that number grew to over 270 million users by 2015.[^13]  The combination of the new communications technology with the timeless human search for relationships led to the launch of Match.com in 1995.  The success of online dating was instantly obvious and in 2002, Wired Magazine prophetically stated, "Twenty years from now, the idea that someone looking for love won't look for it online will be silly, akin to skipping the card catalog to instead wander the stacks because the right books are found only by accident."[^14]  Since that article was written, more than 49 million Americans have tried online dating and approximately 17% of marriages in the last year were products of online dating.[^15]

[^8]:  https://www.wired.com/2014/08/tech-time-warp-ibm-1401-dating/
[^9]:  Id.
[^10]: http://www.businessinsider.com/found-footage-awkward-80s-video-dating-2015-12
[^11]: Id.
[^12]: https://ourworldindata.org/internet/
[^13]: Id.
[^14]: http://www.pbs.org/pov/xoxosms/infographic-technology-dating/
[^15]: https://www.statisticbrain.com/online-dating-statistics/

### Prior Studies

Self-presentation and self-disclosure are well studied aspects of the relational development.  In Erving Goffman's 1959 study "Presentation of Self In Everyday Life", Goffman explores the way way in which individuals use strategic activities to "convey an impression to others which it is in his interest to convey."[^16]  These strategic activities are most important at the beginning of a relationship where an individual will "alter their self-presentational behavior in accordance with the values desired by the prospective date."[^17]  As Rowatt, Cunningham, & Druen noted, "men, but no women, chang[ed] their self-reported personality characteristics and physical appearance when they expected to meet a potential date.  Additionally, their propensity to exaggerate these characteristics was enhanced when the method of meeting was via email."[^18]  Dating success, however, is not solely tied to an exaggerated presentation of the ideal self.  Reis and Shaver's research indicated that the need to highlight one's positive attributes are experienced in tandem with the need to present' one's true self.[^19]  Interestingly, research by Gibbs, Ellison, and Heino indicates that 94% individuals disagreed that they had intentionally misrepresented themselves in their online communication and 87% felt that intentionally misrepresenting one's self to was unacceptable.[^20]  

Somewhat contradicting prior research, 2010 research by Hitsch, Hortacsu, and Airely found no evidence for strategic behavior.[^21]  Their research found strong same-race preferences among users, which did not differ across age, income, or education levels.  The study, however, did show gender differences in mate preferences, specifically that women had stronger preference for income and men had stronger preference for physical attributes.[^22]

Our platform of interest, Tinder, has been the focus of a few published studies. Gatter & Hodkinson found that "despite common stereotypes about those who use different types of online dating...no differences were found in motivations, suggesting that people may use both Online Dating Agencies and Tinder for similar reasons."[^23]  In specifying the motivations behind Tinder use, Sumter, Vandenbosch, and Ligtenberg found six motivating factors for use: Love, Casual Sex, Ease of Communication, Self-Worth Validation, Thrill of Excitement, and Trendiness.[^24]

[^16]: http://clockwatching.net/~jimmy/eng101/articles/goffman_intro.pdf
[^17]: http://onlinelibrary.wiley.com/doi/10.1111/j.1083-6101.2006.00020.x/full
[^18]: https://pdfs.semanticscholar.org/0b3c/a535b2ca4bcb6506d8d579b61b70a41ac961.pdf
[^19]: http://www.affective-science.org/pubs/1998/LaurenFBPl1998.pdf
[^20]: http://journals.sagepub.com/doi/10.1177/0093650205285368
[^21]: https://link.springer.com/article/10.1007/s11129-010-9088-6
[^22]: Id.
[^23]: http://www.tandfonline.com/doi/abs/10.1080/23311908.2016.1162414
[^24]: http://www.sciencedirect.com/science/article/pii/S0736585316301216

## Research Question and Hypothesis

Building upon prior research, our study attempts to answer the question "How does success impact date-ability across the genders?"  As success can be measured in a variety of ways, our study used self-presented education level attainment as a proxy.  While our study is solely focused in online dating, we are encouraged by the findings of Gatter & Hodkinson that our findings may generalize to online and offline dating.

Based upon prior research indicating that women have stronger preference for income and men have stronger preference for physical attributes, we hypothesized that females would experience a smaller change in match rate for the same change in education as compared to males.  Stated more directly: as the male profile's listed education changes from no education to MD, we would expect a greater change in match rate than in the female profile for the same increase in education.



$$ 
\begin{aligned}
H_0:& \:Male\:and\: female\: profile\: receive\: the \:same \:change \:in\: rate \:of \:matches\: with \:changes\: to \:education\\
H_1:& \:The \: female \:profile\: gets \:a \:lower\: change \:in \:match\: rate \:as\: education \:increases\: compared \:to \:the\: male \:profile
\end{aligned}
$$
   

## Research Design 
Our experiment created two fictitious online profiles that mimicked actual user profiles on Tinder.  The profiles were of a male and a female, each 29 years of age.  The profiles included five pictures of each individual in various settings, the individual's name, age, level of education attainment, and a comment stating, "Moving in couple of weeks and looking forward to meeting new people!"

The treatment classes are different levels of educational attainment.  Specifically, whether the individual has earned a PhD, MD, or a Bachelor's Degree.  The control group displayed no educational attainment level in the profile.  

Twenty nine years old was the age selected for the profiles as it gives the individual enough time to plausibly have completed any of the treatment levels of education. Further, it is an age where users were more likely to be looking for long-term relationships, rather than short-term flings.  In each profile's filter settings, the age range of potential suitors was restricted to 24-34.

Based upon prior research, physical attributes tend to be highly significant in partner selection, especially for males, and therefore a single male and a single female were selected for the profile images in order to eliminate variation in match rate based upon aesthetics.  Further, the images used were the same images the individuals had used in prior dating profiles to ensure validity of image selection.

The factitious profiles were displayed over a four week period in the eight largest cities in the United States: New York, Los Angeles, Chicago, Houston, Phoenix, Philadelphia, San Antonio, and San Diego.[^25]  It is important to note that neither individual whose pictures we used had previously used Tinder in any of the test cities, thus reducing the potential for any contamination or bias in the results.  Each profile-educational level combination was displayed to 100 users in each city for a one week period of time in November-December, 2017.  Test subjects were randomly selected by  "swiping right" on every other profile displayed.  It should be noted that Tinder profile viewership was restricted to only those who were chosen as test subjects.  This eliminated the ability for a test subject to view the profile at multiple levels of education.  The only potential for spillover would be by an individual having multiple profiles and having been selected twice as a test subject or by recognizing the profile while viewing Tinder on another user's account. Additonally the research team cross compared a unique identifier for profiles to remove any duplicates.

[^25]: https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population
  
After one week, we returned to the profile to collect data on which users also "swiped right" on our test profile.  This factorial design of two sexes, eight cities, and four education levels allowed for the analysis of different impacts of test conditions across sexes and locations.

Linearly, the research design was: 
$$
R - - 0_1,\; R X_1 - 0_2, \; R X_2 - 0_3, \; R X_3 - 0_4
$$

## Randomization engineering

Gathering a larger sample of profiles gave our analysis more power and confidence in the trends observed from the data. As the power calculations below demonstrate, if the study is conducted with individual suitor profiles as the measurement unit there would be a 95% probability of generating results that lead to the rejection of the null in the presence of a true treatment effect, an exceptionally high power. Alternatively, if the analysis considered the group level, then each city(8), each treatment(4) and each gender (2) would result in a much smaller n of 64 and the power in that experiment would be about 8%. The larger the sample size is the more robust the experiment is to identifying subtle differences in the data.


Taken from P93 in G&G
$$
\begin{aligned}
\beta = \Phi \Bigg(\bigg(\frac{|\mu_t -\mu_c| \sqrt{N}}{2\sigma}\bigg)- \Phi^{-1} \bigg(1- \frac{\alpha}{2}\bigg)\Bigg)\\
\end{aligned}
$$

Applying to our data:
```{r}
#Parameters
alpha = 0.05
mu_c = 100
mu_t = 102
sigma = 15

#calc final - individual level
n_1 = 3000
power_indiv = pnorm(((abs(mu_t-mu_c))*sqrt(n_1))/(2*sigma)-qnorm(1-(alpha/2)))
power_indiv
#calc final - city level (8 cities, M|F, 4 treatments)
n_2 = 8*2*4
power_city = pnorm(((abs(mu_t-mu_c))*sqrt(n_2))/(2*sigma)-qnorm(1-(alpha/2)))
power_city
```

The pilot demonstrated that mannually copying and pasting the details from each suitor's profile prohibited collecting a larger number of profiles. It took about three hours to gather four hundred profiles, meaning just over 2 minutes per profile. The use of automation was a very effective tool that enabled the collection of over five thousand suitor profiles in a four week period, which would have taken one hundred eight five hours by hand. Luckily, the website version of Tinder exactly matched the mobile phone version, greatly streamlining and standardizing the data collection approach. 

The research team wrote scripts in AutoHotKey (PC) and Maestro (the MAC equivalent) that control the operating system of the computer. The code would open up Tinder and navigate to developers' tools where the website's Javascript rendered source code (the HTML behind the webpage) was available. The source code listed the suitors name, age, a unique photo source path, and two details about the profile. After collecting and storing the source code in the appropriate folder that designated the city and treatment level, the code would automatically right swipe on the profile collect. 

Tinder restricts users from seeing repeat profiles to prevent communication between people who previously interacted unsuccessfully, making the trials independent. Each week a new randomly selected batch of ladies and gentlemen were swiped on and put into the experiment. Any user of the Tinder application is subject to the behind the scences algorithm that serves up potential profiles; both the test male and female profiles, along with the profiles of the general Tinder user.

To further enhance the level of randomness within treatment assignment, every other profile was systematically rejected from the experiment. Given more time, the treatments could be delivered in alternative orders to help determine if the algorithm modifies the suitor population based on features of the profile. As the experiment was constrained to a five week window, the collection of covariate distributions augments the research team's understanding of the mechanisms driving tinder matches. For example, to help demonstrate the balance in treatment assignment, the distribution of suitor ages for each treatment condition are displayed in figures XX-XX below.

```{r, echo = FALSE}
#setwd("~/Personal/Grad SChool/Courses/w241/Experiment")
df = read.csv("Dating_experiment-Final_Project_DataFV.csv")
#df = read.csv("~/Desktop/Dating_experiment-Final_Project_DataFV2.csv")
#head(df)
```

```{r echo=FALSE, message=FALSE}
robustSEs <- function(my.model){
  my.model$vcovHC <- vcovHC(my.model)
  my.model.summary <- coeftest(my.model, my.model$vcovHC)
  return(my.model.summary)
}
```

```{r echo=FALSE, message=FALSE, fig.width = 11.5, fig.heights = 5}
par(mfrow = c(2,2))
hist(df$age[df$noedu==1], main="Fig. X: Suitor Ages for the No Education Treatment", xlab="Age (years)")
hist(df$age[df$bs==1], main="Fig. X: Suitor Ages for the BS Treatment", xlab="Age (years)")
hist(df$age[df$md==1], main="Fig. X: Suitor Ages for the MD Treatment", xlab="Age (years)")
hist(df$age[df$phd==1], main="Fig. X: Suitor Ages for the PhD Treatment", xlab="Age (years)")
```
 
```{r echo=FALSE, message=FALSE, fig.width = 11, fig.height=4}
par(mfrow = c(1,2))
hist(df$age[df$female==1], main="Fig. X: Distribution of Male Suitor Ages", xlab="Age (years)")
hist(df$age[df$female==0], main="Fig. X: Distribution of Female Suitor Ages", xlab="Age (years)")
```


```{r echo=FALSE, message=FALSE, fig.width = 11.5}
#i don't think we need this
#par(mfrow = c(2,4))
#hist(df$age[df$chicago==1])
#hist(df$age[df$houston==1])
#hist(df$age[df$losangeles==1])
#hist(df$age[df$newyork==1])
#hist(df$age[df$philadelphia==1])
#hist(df$age[df$phoenix==1])
#hist(df$age[df$sanantonio==1])
#hist(df$age[df$sandiego==1])
```

It is interesting to see that the age distribution has a right skew for all treatment conditions, and it is unclear that depending on Tinder to select suitors is truly random-- it could be the case that Tinder selects suitors based on the age or age filter set in the test profile, that older suitors were more likely to artifically reduce their age (paid accounts for those age 29 and above were twice as expensive), or that the general population of Tinder users is centered around the mid-20s age range.  But the consistency of this distribution across all conditions indicates that there was indeed an equal probability of receiving a given treatment condition, at least amongst the suitors selected by Tinder. 

The age distribution of suitors to the Male profile (female suitors) does seem to be centered approximately 2 years younger than that of suitors to the Female profile (shown in Figures XX-XX), and the skew appears to increase slightly with increasing education level.  However, statistical tests for the difference in average age by test condition yields a significant difference only between the male and female conditions (shown in figures XX-XX below), and its effect size is small-- approximately half a year.  Furthermore, since the treatment assignment was randomized within each city and within each gender, this study is generally less concerned with covariate imbalances between cities and between genders.

```{r echo=FALSE, message=FALSE}
agemodel.gender <- lm(age ~ female, data=df)
agemodel.gender.summary <- robustSEs(agemodel.gender)
agemodel.gender.SEs <- c(agemodel.gender.summary[3], agemodel.gender.summary[4])
```

```{r echo=FALSE, message=FALSE}
agemodel.treatment <- lm(age ~ bs + md + phd, data=df)
agemodel.treatment.summary <- robustSEs(agemodel.treatment)
agemodel.treatment.SEs <- c(agemodel.gender.summary[5], agemodel.gender.summary[6], agemodel.gender.summary[7], agemodel.gender.summary[8])
```

```{r echo=FALSE, message=FALSE}
agemodel.city <- lm(age ~ houston + losangeles + newyork + philadelphia + phoenix + sanantonio + sandiego, data=df)
agemodel.city.summary <- robustSEs(agemodel.city)
agemodel.city.SEs <- c(agemodel.city.summary[9], agemodel.city.summary[10], agemodel.city.summary[11], agemodel.city.summary[12], agemodel.city.summary[13], agemodel.city.summary[14], agemodel.city.summary[15], agemodel.city.summary[16])
```

```{r results="asis", echo=FALSE, message=FALSE}
stargazer(agemodel.gender.summary, agemodel.treatment.summary,agemodel.city.summary, se=list(agemodel.gender.SEs, agemodel.treatment.SEs, agemodel.city.SEs), type = "latex", report = "vcs*", single.row = T, column.labels = c("Gender","Treatment", "Location"), title ="Comparison of Average Age")
#cat("\n\n\\pagebreak\n")
```


## Experimental materials (e.g. treatment materials)
Objectively measuring individual's success in life is ambiguous and difficult, but a reasonably good proxy for research purposes could be educational attainment, job title prestige or educational institution prestige.  Below is a table of potential example degrees of variation for each of the proposed measures of success:

+-----------------------------------+---------------+-------------------------------------+
| Educational Attainment            |	Job Title   |	Educational Prestige (nearest)    |
+===================================+===============+=====================================+
| Advanced Degree (JD, PhD, MD, etc)| Doctor        | IVY (Harvard)                       |
+-----------------------------------+---------------+-------------------------------------+
| College Degree	                | Teacher	    | State School (UMass)                |
+-----------------------------------+---------------+-------------------------------------+
| Associate Degree	                | Social Worker	| Community College (Bunker Hill CC)  |
+-----------------------------------+---------------+-------------------------------------+

As a team we considered the strengths and weakness of each respective success measure.  We planned on customizing the education institution to reflect broadly known schools in the vicinity of each city in the experiment. To enhance consistency of school selection across geography, Barron's Ranking list and the US News school ranking would have been consulted. One of the drawbacks of educational prestige that could not be remedied, however, was that educational prestige is most often determined while the individual is in their early twenties. At such a young age the future of any person is extremely malleable and fertility concerns are not particularly potent.  Generally, it also takes time after obtaining an undergraduate education to become particularly skilled or develop expertise or to develop a positive reputation in a domain of interest. Due the inadequacy of using educational prestige as a proxy for success, the research team leaned away from using it as a treatment group in the study.

Professions then appeared as the better measure for success as individual's career paths are more fleshed out a few years later. Most adults know that doctors make significantly more than teachers who make more than social workers, however, all three professions are in the business of helping people, and this could introduce potential bias. To elaborate on that point about bias, men might seek women with a nurturing profession (picturing the woman raising babies at home) and women might avoid men for fear of being replaced in the traditional household roles. Additionally researchers at Microsoft recently published a paper demonstrating gender-based job title bias in the general public's vernacular, implying that using job title as a proxy for success potentially introduces bias into an experiment (Bolukbasi, 2016).  Ultimately, professions each carry their own reputation and predefined characteristics and controlling for that would be exceptionally difficult. Additionally, the novelty effect for women and men in unconventional roles also raised some concerns. Cross comparing average salary data from the Occupation Employment Statistics Survey and the Current Population Survey reveal that top paying professions are male dominated. For example, the Bureau of Labor Statistics data shows that 66% of dentists, 64% of lawyers, and 73% of CEOs are men. Meaning that any high paying job selected would be more common among male profiles than female profiles making an apples to apples cross gender comparison questionable. For these reasons, job title was disregarded as the the final success proxy.

The government and society have created very clear breaks in educational attainment that are known to all, uniform across geographic lines, and would be easy to administer for an experiment. Generally people perceive access to education in the United States as exceptionally balanced across gender, and bias concerns are mitigated. As the graph below indicates, on average there is a positive association between higher education and income levels, providing some validation for the positive life impact.  After deciding to run the experiment with educational attainment as the measure of success, the degrees of treatment were identified as MD, BS, and PhD. The research team was particularly interested in the difference between the impact of having a Medical Degree versus having a Research Degree. Both degrees require about five years to obtain, however there is significant difference in expected earnings. Due to concerns regarding the realness of the profile and limited time, the team decided not to test the impact of the associate's degree because other profiles on Tinder did not prominently display an associate's degree. The control group would be a profile giving no information for the particular success measure. The treatments were delivered in the following non-monotonic order: MD, BS, no education, and PhD. 

In order to effectively deliver the treatment variable, showing the profile to a limited audience of potential suitors was paramount. To elaborate on that point, should a potential suitor see the profile change from "MD" to "BS" that would not only ruin the data point, but also risk the injured party flagging the account to the administrators and terminating the experiment prematurely. Fortunately, the premium Tinder account enabled the research team to control who had access to the profile so only the one hundred individuals in each city selected for that week's treatment were exposed- effectively elminating almost all potential spillover.



```{r, echo = FALSE, fig.height = 3, fig.width = 10}
degree = c("Secondary Education", "Associate's Degree","Bachelor's Degree","Master's Degree", "Research Doctorate","Doctor of Law", "MBA", "Doctor of Medicine" )
salary = c(51500,57100,79800,87700,94100,107000,118300,161200)

df_treatments = as.data.frame(cbind(degree,as.numeric(salary)))

df_treatments <- within(df_treatments, 
                     Position <- factor(df_treatments$degree, 
                                        levels=names(sort(table(df_treatments$degree), 
                                                          decreasing=TRUE))))

 #Plot visual -cnt
 ggplot(data = df_treatments, aes(x=degree, y = salary)) +
   ggtitle(label="Salary by Education Level")+
   geom_bar(stat = "identity", fill ='slategray2') +
   #geom_text(aes(label = format(salary, big.mark = ","), y = salary +400)) +
   scale_x_discrete(labels =function(degree) str_wrap(degree, width = 5)) +
   ylab("Salary($USD)") +
   xlab("Highest Education Level Completed") +
   theme_minimal()
   
 #colnames(grouped_data)= c("Salary Band", "Employee Count","Pct of Non Mgmt")

 #labels were cutoff
#barplot(as.numeric(df_treatments[,"salary"]), main="Salary by Education Level", xlab="Education", ylab="Salary ($)", names.arg=df_treatments[,"degree"])


```

The potential suitors were shown a profile that either read: "MD", "PhD", "BS" or the field to provide education information was left blank. A sample profile can be seen below.

```{r, echo = FALSE}
library(png)
library(grid)
img <- readPNG("sample_profile.png")
grid.raster(img)
```

```{r, fig.width = 12}
#not sure what's intended with these images
layout(matrix(1:2,nr=1,byr=T))
plot(grid.raster(img),xlim=c(1,4),ylim=c(1,4))
plot(grid.raster(img),xlim=c(1,4),ylim=c(1,4))
#plot(readPNG(img))
#plot(readPNG(img))
#plot(readPNG(img))
#plot(readPNG(img))
```



## Measurement of variables
As discussed previously, the treatment in this experiment is the test profile's exposure of a given education level to a potential suitor, and the outcome is whether or not the suitor matches with the test profile.  When applying an education level treatment to the test profile, the measured test subject covariates include its age, sex, and location, and the measured suitor covariates include age, sex, whether or not school information is provided, whether or not job information is provided, and whether or not instagram photos are provided (and their count, if so).  These variables are described in table \textbf{XX} below.

```{r, echo = FALSE, message=FALSE, results="asis"}
#(kalvin) i tried to use kable and kableExtra to format the table, but i'm having trouble using kableExtra
#(kalvin) i might try a different package later

column_names <- c("Variable", "Variable Type", "Source", "Description / Possible Values")
variables <- c("test profile education level", "suitor profile match", "test profile sex", 
               "test profile location", "suitor age", "suitor school***", "suitor job***", 
               "suitor instagram***", "number of instagram photos***")
variable_type <- c("treatment", "outcome", "covariate", "covariate", "covariate", 
                   "covariate", "covariate", "covariate", "covariate")
source <- c("test profile", "Tinder application", "test profile", "test profile", 
            "suitor source code", "suitor source code", "suitor source code", 
            "suitor source code", "suitor source code")
description <- c("4 possible values*: No education listed (control), Bachelor's, MD, PhD", 
                 "2 possible values: match or no match", 
                 "2 possible values: female or male", 
                 "8 possible values: Chicago, Houston, Los Angeles, New York, Philadelphia, Phoenix, San Antonio, San Diego", 
                 "Due to the filters set in the test profiles, this variable can range from 24 - 34 years.", 
                 "2 possible values: school information was detected or not", 
                 "2 possible values: job information was detected or not", 
                 "2 possible values: suitor profile included an instagram link or not", 
                 "if a suitor profile contained a link to an instagram account, this variable is the number of photos in the account")
variables_table <- matrix(c(variables, variable_type, source, description), nrow=length(variables))
#variables_table.app <- cbind(variables_table, source)
colnames(variables_table) <- column_names
print(xtable(variables_table, digits=c(0,0,2,2,2)), type="latex")
```

\* The initial experimental plan also included the 'Associates' education level as a treatment condition, however, technical issues at the start of the experiment prevented proper execution of the 'PhD' education level treatment, so the 'PhD' education level treatment was repeated and the 'Associates' education level treatment was skipped.

\** The test profile age was an originally planned covariate, but due to time constraints, only one age was used for the entire experiment.

\*** These variables are believed to be only partially observed-- see Section \textbf{XX} for further details.


_Issues with Measurement of Outcome_

After swiping right on a suitor, the Tinder application only provides notification if that suitor likes the test profile in return, and does not provide an indication of whether or not a suitor actually saw the profile or if the suitor disliked the test profile.  Our experiment therefore contains some rate of non-compliance and we are unfortunately unable to determine the compliance rate-- our estimated average treatment effect is thus the effect of the intent to treat.

The intent to treat effect is in fact the result of interest.  In practical terms, it describes the effect on match rate a Tinder user should expect when listing a certain education level in his or her profile.  The complier average causal effect, on the other hand, would describe the likelihood that someone swipes right after seeing a certain education level, which is not the research question under examination.


_Issues with Measurement of Covariates_

The structure of the relevant source code in the Tinder browser interface is such that it contains a link to a suitor's profile image (which we use as a unique identifier for that suitor), the suitor's name, the suitor's age, and finally a maximum of two additional details that may include any combination of school information, job information, and instagram information.

It is known that a Tinder profile may display all three of these pieces of information, but none of the source codes collected contained more than two details.  It is highly unlikely that amongst the 6200 suitors encountered in the experiment, none displayed more than two of these details, so we believe that school information, job information, and instagram information are only partially observed, and without more in-depth examination of each suitor profile at the time of experiment execution, our analysis is unable to fully determine the education and job status/level, as well as instagram information, for each suitor.  Due to time and manpower constraints, thorough examination of each profile was unfortunately not an option-- we were required to use an automated swiping method, which acquired covariate information from source code.  It is also known that a Tinder profile may additionally display the suitor's distance and favorite spotify songs, but none of this information was present in the suitor source codes acquired during the experiment, and these two covariates were thus unobserved.

The source code indicates which suitor details are the profile image, the name, and the age, but does not indicate which details are school, job, or instagram information.  Our data collection process searches the text of these details to make a best guess as to what type of detail it is (instagram information is easily identified, but not school or job information).  So for some of the school and job details that were collected, it could not be determined whether the detail represented education or employment in a university setting.


## Modeling choices
calculation of statistical power

## Experiment Results
In text description of your results
Figures and tables that support your in text description
Clean, clear, well articulated relationships between your theory, your hypotheses, the numbers that your models produce, and the figures you present

```{r echo=FALSE}
#removing missing values
#for(i in 1:ncol(df)){
#  x = df[,i]
#  if(is.character(df[,i])){
#    df[,i][is.na(x) | nchar(x) == 0] = 'not available'
#  } else if(is.numeric(df[,i])){
#    df[,i][is.na(x)] = 0.0001  # didn't want too small of a number because of scaling function later
#  }
#}
```


### Exporatory Data Analysis 

The randomization of our treatment assignment was dependent on Tinder's selection of suitors.  Since Tinder's algorithm for this selection is unknown and potentially complex, the team was interested in how the available covariates were balanced across test conditions.

```{r echo=FALSE, message=FALSE}
df$age_indicator <- 1.0*(!is.na(df$age))
df$ig_indicator <- 1.0*(!is.na(df$num_ig))
```

### Missing Instagram Information

Like school and job information, instagram information was missing from many of our suitor profiles.  However, it was easily detected when present in the source code since the format for an instagram detail was consistent across suitor profiles (of the form "X Instagram Photos").  One technical detail of the structure of suitor source codes is that school and job information took priority-- an instagram detail is only present when less than two school or job details are present.  Therefore, whether or not a profile's source code contains an instagram detail could be used to represent the amount of information a suitor chose to include in his or her profile-- the missingness of instagram details is thus examined across experimental conditions.  Table XXX below shows the count of profiles with instagram information detected between the male and female test profiles.

```{r results="asis", echo=FALSE, message=FALSE}
missing.ig.female <- 100*(1-mean(df$ig_indicator[df$female==1]))
missing.ig.male <- 100*(1-mean(df$ig_indicator[df$female==0]))
#table(df[,c('female','ig_indicator')])
total.female <- sum(df$female==1)
total.male <- sum(df$female==0)
num.ig.female <- sum(df$ig_indicator[df$female==1])
num.ig.male <- sum(df$ig_indicator[df$female==0])

column.names <- c("Gender", "Total Profiles", "Profiles with Instagram", "% Missing Instagram Info")
column.1 <- c("Female", "Male")
column.2 <- c(total.female, total.male)
column.3 <- c(num.ig.female, num.ig.male)
column.4 <- c(missing.ig.female, missing.ig.male)
missing.ig.table <- matrix(c(column.1, column.2, column.3, column.4), nrow=length(column.1))
colnames(missing.ig.table) <- column.names
print(xtable(missing.ig.table, digits=c(0,0,2,2,2)), type="latex")#setting decimal places doesn't seem to be working
```

```{r echo=FALSE, message=FALSE}
ig.gender <- lm(ig_indicator ~ female, data=df)
ig.gender.summary <- robustSEs(ig.gender)
ig.gender.SEs <- c(ig.gender.summary[3], ig.gender.summary[4])
```

Table XXX below shows the count of profiles with instagram information detected between all treatment conditions.

```{r results="asis", echo=FALSE, message=FALSE}
missing.ig.noedu <- 100*(1-mean(df$ig_indicator[df$noedu==1]))
missing.ig.bs <- 100*(1-mean(df$ig_indicator[df$bs==1]))
missing.ig.md <- 100*(1-mean(df$ig_indicator[df$md==1]))
missing.ig.phd <- 100*(1-mean(df$ig_indicator[df$phd==1]))
total.noedu <- sum(df$noedu==1)
total.bs <- sum(df$bs==1)
total.md <- sum(df$md==1)
total.phd <- sum(df$phd==1)
num.ig.noedu <- sum(df$ig_indicator[df$noedu==1])
num.ig.bs <- sum(df$ig_indicator[df$bs==1])
num.ig.md <- sum(df$ig_indicator[df$md==1])
num.ig.phd <- sum(df$ig_indicator[df$phd==1])

column.names <- c("Education Level", "Total Profiles", "Profiles with Instagram", "% Missing Instagram Info")
column.1 <- c("No Education", "BS", "MD", "PhD")
column.2 <- c(total.noedu, total.bs, total.md, total.phd)
column.3 <- c(num.ig.noedu, num.ig.bs, num.ig.md, num.ig.phd)
column.4 <- c(missing.ig.noedu, missing.ig.bs, missing.ig.md, missing.ig.phd)
missing.ig.table <- matrix(c(column.1, column.2, column.3, column.4), nrow=length(column.1))
colnames(missing.ig.table) <- column.names
print(xtable(missing.ig.table, digits=c(0,0,2,2,2)), type="latex")#setting decimal places doesn't seem to be working
```

```{r echo=FALSE, message=FALSE}
ig.treatment <- lm(ig_indicator ~ bs + md + phd, data=df)
ig.treatment.summary <- robustSEs(ig.treatment)
ig.treatment.SEs <- c(ig.treatment.summary[5], ig.treatment.summary[6], ig.treatment.summary[7], ig.treatment.summary[8])
```

Table XXX below shows the count of profiles with instagram information detected between all testing locations.

```{r results="asis", echo=FALSE, message=FALSE}
missing.ig.chicago <- 100*(1-mean(df$ig_indicator[df$chicago==1]))
missing.ig.houston <- 100*(1-mean(df$ig_indicator[df$houston==1]))
missing.ig.losangeles <- 100*(1-mean(df$ig_indicator[df$losangeles==1]))
missing.ig.newyork <- 100*(1-mean(df$ig_indicator[df$newyork==1]))
missing.ig.philadelphia <- 100*(1-mean(df$ig_indicator[df$philadelphia==1]))
missing.ig.phoenix <- 100*(1-mean(df$ig_indicator[df$phoenix==1]))
missing.ig.sanantonio <- 100*(1-mean(df$ig_indicator[df$sanantonio==1]))
missing.ig.sandiego <- 100*(1-mean(df$ig_indicator[df$sandiego==1]))
total.chicago <- sum(df$chicago==1)
total.houston <- sum(df$houston==1)
total.losangeles <- sum(df$losangeles==1)
total.newyork <- sum(df$newyork==1)
total.philadelphia <- sum(df$philadelphia==1)
total.phoenix <- sum(df$phoenix==1)
total.sanantonio <- sum(df$sanantonio==1)
total.sandiego <- sum(df$sandiego==1)
num.ig.chicago <- sum(df$ig_indicator[df$chicago==1])
num.ig.houston <- sum(df$ig_indicator[df$houston==1])
num.ig.losangeles <- sum(df$ig_indicator[df$losangeles==1])
num.ig.newyork <- sum(df$ig_indicator[df$newyork==1])
num.ig.philadelphia <- sum(df$ig_indicator[df$philadelphia==1])
num.ig.phoenix <- sum(df$ig_indicator[df$phoenix==1])
num.ig.sanantonio <- sum(df$ig_indicator[df$sanantonio==1])
num.ig.sandiego <- sum(df$ig_indicator[df$sandiego==1])

column.names <- c("City", "Total Profiles", "Profiles with Instagram", "% Missing Instagram Info")
column.1 <- c("Chicago", "Houston", "Los Angeles", "New York", "Phildelphia", "Phoenix", "San Antonio", "San Diego")
column.2 <- c(total.chicago, total.houston, total.losangeles, total.newyork, 
              total.philadelphia, total.phoenix, total.sanantonio, total.sandiego)
column.3 <- c(num.ig.chicago, num.ig.houston, num.ig.losangeles, num.ig.newyork, 
              num.ig.philadelphia, num.ig.phoenix, num.ig.sanantonio, num.ig.sandiego)
column.4 <- c(missing.ig.chicago, missing.ig.houston, missing.ig.losangeles, missing.ig.newyork, 
              missing.ig.philadelphia, missing.ig.phoenix, missing.ig.sanantonio, missing.ig.sandiego)

missing.ig.table <- matrix(c(column.1, column.2, column.3, column.4), nrow=length(column.1))
colnames(missing.ig.table) <- column.names
print(xtable(missing.ig.table, digits=c(0,0,2,2,2)), type="latex")#setting decimal places doesn't seem to be working
```

```{r echo=FALSE, message=FALSE}
ig.city <- lm(ig_indicator ~ houston + losangeles + newyork + philadelphia + phoenix + sanantonio + sandiego, data=df)
ig.city.summary <- robustSEs(ig.city)
ig.city.SEs <- c(ig.city.summary[9], ig.city.summary[10], ig.city.summary[11], ig.city.summary[12], ig.city.summary[13], ig.city.summary[14], ig.city.summary[15], ig.city.summary[16])
```

Table XXX below shows the results of the tests for a difference in average missingness of instagram information, by gender, treatment condition, and location.  While some differences are statistically significant, we do not consider them practically significant-- the missingess of instagram information seems to be balanced across test conditions.

```{r results="asis", echo=FALSE, message=FALSE}
stargazer(ig.gender.summary, ig.treatment.summary,ig.city.summary, se=list(ig.gender.SEs, ig.treatment.SEs, ig.city.SEs), type = "latex", report = "vcs*", single.row = T, column.labels = c("Gender","Treatment", "Location"), title ="Comparison of IG Missingness")
#cat("\n\n\\pagebreak\n")
```

### Missing Age Values

Table XXX below shows the count of profiles that contain the suitor's age, between males and females.

```{r results="asis", echo=FALSE, message=FALSE}
missing.age.female <- 100*(1-mean(df$age_indicator[df$female==1]))
missing.age.male <- 100*(1-mean(df$age_indicator[df$female==0]))

total.female <- sum(df$female==1)
total.male <- sum(df$female==0)
num.age.female <- sum(df$age_indicator[df$female==1])
num.age.male <- sum(df$age_indicator[df$female==0])

column.names <- c("Gender", "Total Profiles", "Profiles with Age", "% Missing Age")
column.1 <- c("Female", "Male")
column.2 <- c(total.female, total.male)
column.3 <- c(num.age.female, num.age.male)
column.4 <- c(missing.age.female, missing.age.male)
missing.age.table <- matrix(c(column.1, column.2, column.3, column.4), nrow=length(column.1))
colnames(missing.age.table) <- column.names
print(xtable(missing.age.table, digits=c(0,0,2,2,2)), type="latex")#setting decimal places doesn't seem to be working
```

```{r echo=FALSE, message=FALSE}
age.gender <- lm(age_indicator ~ female, data=df)
age.gender.summary <- robustSEs(age.gender)
age.gender.SEs <- c(age.gender.summary[3], age.gender.summary[4])
```

Table XXX below shows the count of profiles that contain the suitor's age, between all treatment conditions.

```{r results="asis", echo=FALSE, message=FALSE}
missing.age.noedu <- 100*(1-mean(df$age_indicator[df$noedu==1]))
missing.age.bs <- 100*(1-mean(df$age_indicator[df$bs==1]))
missing.age.md <- 100*(1-mean(df$age_indicator[df$md==1]))
missing.age.phd <- 100*(1-mean(df$age_indicator[df$phd==1]))
total.noedu <- sum(df$noedu==1)
total.bs <- sum(df$bs==1)
total.md <- sum(df$md==1)
total.phd <- sum(df$phd==1)
num.age.noedu <- sum(df$age_indicator[df$noedu==1])
num.age.bs <- sum(df$age_indicator[df$bs==1])
num.age.md <- sum(df$age_indicator[df$md==1])
num.age.phd <- sum(df$age_indicator[df$phd==1])

column.names <- c("Education Level", "Total Profiles", "Profiles with Age", "% Missing Age")
column.1 <- c("No Education", "BS", "MD", "PhD")
column.2 <- c(total.noedu, total.bs, total.md, total.phd)
column.3 <- c(num.age.noedu, num.age.bs, num.age.md, num.age.phd)
column.4 <- c(missing.age.noedu, missing.age.bs, missing.age.md, missing.age.phd)
missing.age.table <- matrix(c(column.1, column.2, column.3, column.4), nrow=length(column.1))
colnames(missing.age.table) <- column.names
print(xtable(missing.age.table, digits=c(0,0,2,2,2)), type="latex")#setting decimal places doesn't seem to be working
```

```{r echo=FALSE, message=FALSE}
age.treatment <- lm(age_indicator ~ bs + md + phd, data=df)
age.treatment.summary <- robustSEs(age.treatment)
age.treatment.SEs <- c(age.treatment.summary[5], age.treatment.summary[6], age.treatment.summary[7], age.treatment.summary[8])
```

Table XXX below shows the count of profiles that contain the suitor's age, between all testing locations.

```{r results="asis", echo=FALSE, message=FALSE}
missing.age.chicago <- 100*(1-mean(df$age_indicator[df$chicago==1]))
missing.age.houston <- 100*(1-mean(df$age_indicator[df$houston==1]))
missing.age.losangeles <- 100*(1-mean(df$age_indicator[df$losangeles==1]))
missing.age.newyork <- 100*(1-mean(df$age_indicator[df$newyork==1]))
missing.age.philadelphia <- 100*(1-mean(df$age_indicator[df$philadelphia==1]))
missing.age.phoenix <- 100*(1-mean(df$age_indicator[df$phoenix==1]))
missing.age.sanantonio <- 100*(1-mean(df$age_indicator[df$sanantonio==1]))
missing.age.sandiego <- 100*(1-mean(df$age_indicator[df$sandiego==1]))
total.chicago <- sum(df$chicago==1)
total.houston <- sum(df$houston==1)
total.losangeles <- sum(df$losangeles==1)
total.newyork <- sum(df$newyork==1)
total.philadelphia <- sum(df$philadelphia==1)
total.phoenix <- sum(df$phoenix==1)
total.sanantonio <- sum(df$sanantonio==1)
total.sandiego <- sum(df$sandiego==1)
num.age.chicago <- sum(df$age_indicator[df$chicago==1])
num.age.houston <- sum(df$age_indicator[df$houston==1])
num.age.losangeles <- sum(df$age_indicator[df$losangeles==1])
num.age.newyork <- sum(df$age_indicator[df$newyork==1])
num.age.philadelphia <- sum(df$age_indicator[df$philadelphia==1])
num.age.phoenix <- sum(df$age_indicator[df$phoenix==1])
num.age.sanantonio <- sum(df$age_indicator[df$sanantonio==1])
num.age.sandiego <- sum(df$age_indicator[df$sandiego==1])

column.names <- c("City", "Total Profiles", "Profiles with Age", "% Missing Age")
column.1 <- c("Chicago", "Houston", "Los Angeles", "New York", "Phildelphia", "Phoenix", "San Antonio", "San Diego")
column.2 <- c(total.chicago, total.houston, total.losangeles, total.newyork, 
              total.philadelphia, total.phoenix, total.sanantonio, total.sandiego)
column.3 <- c(num.age.chicago, num.age.houston, num.age.losangeles, num.age.newyork, 
              num.age.philadelphia, num.age.phoenix, num.age.sanantonio, num.age.sandiego)
column.4 <- c(missing.age.chicago, missing.age.houston, missing.age.losangeles, missing.age.newyork, 
              missing.age.philadelphia, missing.age.phoenix, missing.age.sanantonio, missing.age.sandiego)

missing.age.table <- matrix(c(column.1, column.2, column.3, column.4), nrow=length(column.1))
colnames(missing.age.table) <- column.names
print(xtable(missing.age.table, digits=c(0,0,2,2,2)), type="latex")#setting decimal places doesn't seem to be working
```

```{r echo=FALSE, message=FALSE}
age.city <- lm(age_indicator ~ houston + losangeles + newyork + philadelphia + phoenix + sanantonio + sandiego, data=df)
age.city.summary <- robustSEs(age.city)
age.city.SEs <- c(age.city.summary[9], age.city.summary[10], age.city.summary[11], age.city.summary[12], age.city.summary[13], age.city.summary[14], age.city.summary[15], age.city.summary[16])
```

Table XXX below shows the results of the tests for a difference in average missingness of the suitor's age, by gender, treatment condition, and location.  While some differences are statistically significant (between males and females, for example), we do not consider them practically significant.  It appears that the missingess of age information is also balanced across test conditions.

```{r results="asis", echo=FALSE, message=FALSE}
stargazer(age.gender.summary, age.treatment.summary,age.city.summary, se=list(age.gender.SEs, age.treatment.SEs, age.city.SEs), type = "latex", report = "vcs*", single.row = T, column.labels = c("Gender","Treatment", "Location"), title ="Comparison of Age Missingness")
#cat("\n\n\\pagebreak\n")
```

The important result of the exploratory data analysis is that no significant difference in covariates was found between treatments, so the experiment still yields an apples-to-apples comparison.

```{r}
#NEED FOR REGRESSIONS + POWER CALC
#prep data
df_female = subset(df, df$female == 1)
#changes missing values to something easier to delete (done later)
df_female[,"age"][is.na(df_female[,"age"])] = 0.0001
df_female = subset(df_female, df_female$age != 0.0001)
library(sandwich)
library(lmtest)
```

Results:
As a research team we were extremely excited to see any kind of results. In the pilot and in the first round of testing we struggled with a low overall match rate (0/400 swipes and 5/1,600 respectively) and therefore we could not perform initial calculations to evaluate the treatments' effect. The primary concern was that the Tinder user made decisions based solely on physical attractiveness and there would be no variance across our treatment variable. It wasn't until week four of swiping that we could compare the numbers across treatments. Unfortunately the data points from the pilot and the second week of the project would have introduced too much bias because the profiles were modified thereafter; so the data was excluded from the analysis.

After enhancing the profiles in week three more matches finally came in. The two tables below summarize the match distribution across key variables.  The first table highlights the extreme imbalance across gender where the female profile received almost forty four times the number of matches compared to the male profile. The second table displays the match rate across the treatment groups and that the higher education levels were associated with higher match rates.  The high level figures intimate a causal treatment effect, but more robust calculations must be performed before that claim can be made.

High Level Overview of Outcomes
```{r, echo = FALSE}
cnts = table(df$Matched, df$female, dnn=c("Matches","Female Indicator"))
addmargins(cnts)
```

```{r, echo = FALSE}
##i don't have the treatment column in the df dataframe, so i'm unable to run/knit this
#cnts_treat = table(df$Matched,df$treatment, #dnn=c("Matches", "Treatment"))
#addmargins(cnts_treat)
```

```{r echo=FALSE, message=FALSE, results="asis"}
column.names <- c("", "No Education (Control)", "BS", "MD", "PhD")
column.1 <- c("Matches", "Total Suitors")
column.2 <- c(sum(df$Matched[df$noedu==1]), sum(df$noedu==1))
column.3 <- c(sum(df$Matched[df$bs==1]), sum(df$bs==1))
column.4 <- c(sum(df$Matched[df$md==1]), sum(df$md==1))
column.5 <- c(sum(df$Matched[df$phd==1]), sum(df$phd==1))

treatment.match.table <- matrix(c(column.1, column.2, column.3, column.4, column.5), nrow=length(column.1))
colnames(treatment.match.table) <- column.names
print(xtable(treatment.match.table), type="latex")#setting decimal places doesn't seem to be working
```
Before building sophisticated models, the research team paused to consider the power of the experiment. While the delta between the treatment and control means was very small, the large sample size engenders a high powered experiment. 

Actual Power of the experiment:
```{r}
#Parameters
alpha = 0.05
mu_c = mean(df_female$Matched[df_female$noedu==1])
mu_c
mu_t = mean((df_female$Matched[df_female$md==1]),na.rm = T)
mu_t
sigma = sd((df_female$Matched[df_female$md==1]),na.rm = T)

#calc final - individual level
n_1 = 3034
power_indiv = pnorm(((abs(mu_t-mu_c))*sqrt(n_1))/(2*sigma)-qnorm(1-(alpha/2)))
power_indiv
```

 
Modeling Choices:
To better understand the predictive power and magnitude of each variable the research team exclusively leveraged regression models. This type of model is known for being highly interpretable and there are many different varieties of regression available. For analyzing our experiment we selected both linear and logistic model implementations. 

Part I Linear Regression:

The first model shown below is a standard ordinary least squares regression where the outcome variable is the linear measurement of the match variable. As the regression table shows, we regressed the match indicator against each of the treatments, the female indicator and we also tested for interactions between the treatment variables and gender. The highest level of education, MD, has a positive and significant ATE of 0.06 for the female account meaning that the number of matches actually increased by 6% when the treatment was applied compared to when the control group with no education information was applied. Prior observational research from match.com indicated that income levels for females was not significant and it is surprising to see a different pattern. The regressions shows there were no other statistically significant variables so the other treatment variables, BS and PhD, did not provide evidence of causal relationships.

Not surprisingly, with only thirteen male matches and over five hundred female matches the data results in a highly significant effect on the female indicator variable where the female match rate is sixteen percent points higher. The research team did not want to draw too many conclusions from the male matched records because any findings would just be p-hacking. In the next series of regressions, all the male records were removed from the regression and the sample size drops from n = 6,269 to n = 3,034. Additionally, the seventy nine suitor profiles without age information were also removed, but as discussed in the EDA section there is no bias introduced with this action.

## Models
$$ 
y_i = {\beta}_0 + {\beta}_1Z_i + e_i \\
Y_{Matches} = \beta_0 + \beta_1 MD + \beta_2 PhD + \beta_3 BS + \beta_4 female + \beta_5 female* MD + \beta_6 female*PhD  + \beta_7 female*BS  + e_i \\
$$

```{r, echo = FALSE, fig.width =11.5}
model_gender = lm(Matched ~ md + bs + phd  + female + female*md + female*bs + female*phd, data = df)
summary(model_gender)
```
 
The research team did have some concerns regarding the validity of a linear regression with a binary outcome variable. With any regression model it is important to consider the BLUE assumptions, which is exactly what the plots below explore:

```{r, echo = FALSE, fig.width =11.5, fig.height = 8}
par(mfrow = c(2,2))
plot(model_gender, which = c(1,2,3,5))
```
To address the violated homoskedacity seen the in residuals vs fitted  and scale-location graphs above, gender model 2 uses robust standard errors, but the coefficient estimates are still the same. More importantly, the female MD treatment is still statistically significant even with a wider confidence interval generated with the robust standard errors.
```{r}
library(sandwich)
model_gender2 = coeftest(model_gender, vcov = vcovHC)
model_gender2
```

The results from the prior page are included as the base model in column one, but the research team wanted to add additional covariates to the model little by little to fully understand their impact. The first variable considered was age; as the suitor profiles increase in age, there is a significant but small decrease in the match rate of -0.5% seen in the model results in column two.  Column three considers a model with location covariates, but unlike in the baseline model, there is no control for location that would be the obvious choice to leave out.  Consequently, the coefficients for location are compared to the values for Chicago. The female profile received significantly more matches in LA than any other city, and Chicago had slightly more matches than the remaining five cities, as indicated by the negative coefficients; however these deltas were not all statistically significant. Column four considers the influence of a suitor writing in a job title or school, but the regression shows the additional covariates do not add bias. Finally column five details a comprehensive model that amalgamates all the covariates. The most important takeaway from these more detailed models is that the MD treatment is highly significant across in every instance.

```{r, fig.width =12, results='asis', message=FALSE}
library(stargazer)
#location model
model_location = lm(Matched ~ md + bs + phd  + losangeles + houston + newyork + phoenix + sandiego +sanantonio +philadelphia, data = df_female)
model_location2 = coeftest(model_location, vcov = vcovHC)
#age
model_age = lm(Matched ~ md + bs + phd  + age  , data = df_female)
model_age2 = coeftest(model_age, vcov = vcovHC)
#details
model_details = lm(Matched ~ md + bs + phd  +  school + job, data = df_female)
model_details2 = coeftest(model_details, vcov = vcovHC)

#all
model_all = lm(Matched ~ md + bs + phd  +  age + losangeles + houston + newyork + phoenix + sandiego +sanantonio +philadelphia +  school + job  , data = df_female)
model_all2 = coeftest(model_all, vcov = vcovHC)
#Change type to "latex" for knitting to pdf or text for R viewing
stargazer(model_gender2, model_age2, model_location2, model_details2, model_all2,type = "latex", report = "vcs*", single.row = T, column.labels = c("Base","Age", "Location", "Details", "All"), title ="Comparison of treatments")
#cat("\n\n\\pagebreak\n")
```
Part II Logistic Regression:
After reviewing the results of five different regression models the research team observed that all of the coefficients very low and we could not shake the feeling that something was off.  After some research we found that models with probabilities close to 0 and 1 are prime candidates for logistic regression. What does it mean for a probability to be close to 1? If you take the results from the baseline model and plug in a test case, for this example consider a male with an MD, the probability of receiving a match is 0.0064 (calculation built off of baseline regression) or practically 0.
$$
\begin{aligned}
p =& 0.0025 + 0.0039 *1 \\
p =&  0.0064
\end{aligned}
$$

We updated our modeling technique to logistic regression to better fit the data. The regression output below shows a consistently statistically significant female indicator, but instead of the model coefficients showing percentage point difference in probability, the logistic model outputs a log odds ratio. This is a very difficult to interpret measure so we exponentiated the coefficients and interpreted them as regular odds-ratios. The coefficient 4.39 for the female indicator actually means the probability of having a match based on that variable alone (see table converting odds ratios to probability for support) is over 90% and this magnitude of influence is much more practically significant than the 16% seen in the Linear model. The other important call out is that the treatment variable interacted with the female indicator is no longer statistically significant. While the regression coefficient now looks negative, it must be converted to an odds ratio. After that transformation, the probability of a match for a female with an MD is actually a positive 35% probability. Based on our original raw numbers we know that the observed MD match rate is closer to 20% and our new model also has a very large weight on the intercept, indicating there is more analysis needed.
```{r, echo = FALSE}
Lmodel_gender = glm(Matched ~ md + bs + phd  + female + female*md + female*bs + female*phd, data = df, family = "binomial")
#Lmodel_gender = glm(matches ~ md + bs + phd  + female +female*md + female*bs + female*phd , data = df, family = "binomial")
summary(Lmodel_gender)
exp(coef(Lmodel_gender))
```
 
```{r, echo = FALSE}
library(png)
library(grid)
img <- readPNG("OddsRatio_scale.PNG")
grid.raster(img)
```

 
To enable comparison with the linear regression model, we dropped the male data and explored the impact of additional covariates in the tables below.  Now if we consider the impact of the MD treatment we see once again that it is significant in all of the covariate models, and the odds ratio hovers around 1.55 or ~ 60% probability. Despite adding several different coefficients, our models still have highly significant intercepts, high AIC values, and a potentially over stated treatment effect. What the logistic regressions imply is that the model may have explanatory power it does not have much predictive power. While we are confident in the causal relationship seen additional endogenous variables likely exist.

```{r, fig.width =12, results='asis', message=FALSE}
library(stargazer)
#prep data
df_female = subset(df, df$female == 1)
#changes missing values to something easier to delete (done later)
df_female[,"age"][is.na(df_female[,"age"])] = 0.0001
df_female = subset(df_female, df_female$age != 0.0001)

#location model
Lmodel_location = glm(Matched ~ md + bs + phd  + losangeles + houston + newyork + phoenix + sandiego +sanantonio +philadelphia,  data = df_female, family = "binomial")
#age
Lmodel_age = glm(Matched ~ md + bs + phd  + age  , data = df_female, family = "binomial")
#details
Lmodel_details = glm(Matched ~ md + bs + phd  +  school + job, data = df_female, family = "binomial")

#all
Lmodel_all = glm(Matched ~ md + bs + phd  +  age + losangeles + houston + newyork + phoenix + sandiego +sanantonio +philadelphia +  school + job  , data = df_female, family = "binomial")
#Change type to "latex" for knitting to pdf
stargazer(Lmodel_gender, Lmodel_age, Lmodel_location, Lmodel_details, Lmodel_all,type = "text", report = "vcs*", single.row = T, column.labels = c("Base","Age", "Location", "Details", "All"), title ="Comparison of treatments")
#cat("\n\n\\pagebreak\n")
```

```{r, echo = FALSE}
#Exponentiated coef dataframe
gender = exp(coef(Lmodel_gender))
age = exp(coef(Lmodel_age))
loc = exp(coef(Lmodel_location))
details = exp(coef(Lmodel_details))
all = exp(coef(Lmodel_all))

df_exponen = cbind(gender, age, loc, details, all)
df_exponen
```

### Randomization Inference

Our results are further confirmed by randomization inference under the sharp null hypothesis that treatments have no effect on any individual-- in other words, this test assumes that the education level shown to each suitor had no effect on whether or not there was a match.  The experiment was blocked on gender and location, so we simulate a new randomization of the treatment assignment within each combination of gender and location, and re-calculate the ATE under that treatment assignment.  For each treatment, we repeat this procedure 10,000 times and compare the aggregated ATE's under simulation with our actual estimate in order to gain a sense of the likelihood of observing our estimates if the treatment did not actually have an effect.

```{r echo=FALSE, message=FALSE}
df.ri <- df[!is.na(df$Matched),]
randomize <- function(n.control, n.treat) sample(c(rep(0,n.control),rep(1,n.treat)))
est.ate <- function(outcome, treat) mean(outcome[treat==1]) - mean(outcome[treat==0])
```

```{r echo=FALSE, message=FALSE}
#chicago
#control
n.chicago.f.noedu <- sum(df.ri$female==1 & df.ri$chicago==1 & df.ri$noedu==1)
o.chicago.f.noedu <- df.ri$Matched[df.ri$female==1 & df.ri$chicago==1 & df.ri$noedu==1]
n.chicago.m.noedu <- sum(df.ri$female==0 & df.ri$chicago==1 & df.ri$noedu==1)
o.chicago.m.noedu <- df.ri$Matched[df.ri$female==0 & df.ri$chicago==1 & df.ri$noedu==1]
#bs
n.chicago.f.bs <- sum(df.ri$female==1 & df.ri$chicago==1 & df.ri$bs==1)
o.chicago.f.bs <- df.ri$Matched[df.ri$female==1 & df.ri$chicago==1 & df.ri$bs==1]
n.chicago.m.bs <- sum(df.ri$female==0 & df.ri$chicago==1 & df.ri$bs==1)
o.chicago.m.bs <- df.ri$Matched[df.ri$female==0 & df.ri$chicago==1 & df.ri$bs==1]
#md
n.chicago.f.md <- sum(df.ri$female==1 & df.ri$chicago==1 & df.ri$md==1)
o.chicago.f.md <- df.ri$Matched[df.ri$female==1 & df.ri$chicago==1 & df.ri$md==1]
n.chicago.m.md <- sum(df.ri$female==0 & df.ri$chicago==1 & df.ri$md==1)
o.chicago.m.md <- df.ri$Matched[df.ri$female==0 & df.ri$chicago==1 & df.ri$md==1]
#phd
n.chicago.f.phd <- sum(df.ri$female==1 & df.ri$chicago==1 & df.ri$phd==1)
o.chicago.f.phd <- df.ri$Matched[df.ri$female==1 & df.ri$chicago==1 & df.ri$phd==1]
n.chicago.m.phd <- sum(df.ri$female==0 & df.ri$chicago==1 & df.ri$phd==1)
o.chicago.m.phd <- df.ri$Matched[df.ri$female==0 & df.ri$chicago==1 & df.ri$phd==1]

#houston female
#control
n.houston.f.noedu <- sum(df.ri$female==1 & df.ri$houston==1 & df.ri$noedu==1)
o.houston.f.noedu <- df.ri$Matched[df.ri$female==1 & df.ri$houston==1 & df.ri$noedu==1]
#bs
n.houston.f.bs <- sum(df.ri$female==1 & df.ri$houston==1 & df.ri$bs==1)
o.houston.f.bs <- df.ri$Matched[df.ri$female==1 & df.ri$houston==1 & df.ri$bs==1]
#md
n.houston.f.md <- sum(df.ri$female==1 & df.ri$houston==1 & df.ri$md==1)
o.houston.f.md <- df.ri$Matched[df.ri$female==1 & df.ri$houston==1 & df.ri$md==1]
#phd
n.houston.f.phd <- sum(df.ri$female==1 & df.ri$houston==1 & df.ri$phd==1)
o.houston.f.phd <- df.ri$Matched[df.ri$female==1 & df.ri$houston==1 & df.ri$phd==1]
#houston male
#control
n.houston.m.noedu <- sum(df.ri$female==0 & df.ri$houston==1 & df.ri$noedu==1)
o.houston.m.noedu <- df.ri$Matched[df.ri$female==0 & df.ri$houston==1 & df.ri$noedu==1]
#bs
n.houston.m.bs <- sum(df.ri$female==0 & df.ri$houston==1 & df.ri$bs==1)
o.houston.m.bs <- df.ri$Matched[df.ri$female==0 & df.ri$houston==1 & df.ri$bs==1]
#md
n.houston.m.md <- sum(df.ri$female==0 & df.ri$houston==1 & df.ri$md==1)
o.houston.m.md <- df.ri$Matched[df.ri$female==0 & df.ri$houston==1 & df.ri$md==1]
#phd
n.houston.m.phd <- sum(df.ri$female==0 & df.ri$houston==1 & df.ri$phd==1)
o.houston.m.phd <- df.ri$Matched[df.ri$female==0 & df.ri$houston==1 & df.ri$phd==1]

#losangeles female
#control
n.losangeles.f.noedu <- sum(df.ri$female==1 & df.ri$losangeles==1 & df.ri$noedu==1)
o.losangeles.f.noedu <- df.ri$Matched[df.ri$female==1 & df.ri$losangeles==1 & df.ri$noedu==1]
#bs
n.losangeles.f.bs <- sum(df.ri$female==1 & df.ri$losangeles==1 & df.ri$bs==1)
o.losangeles.f.bs <- df.ri$Matched[df.ri$female==1 & df.ri$losangeles==1 & df.ri$bs==1]
#md
n.losangeles.f.md <- sum(df.ri$female==1 & df.ri$losangeles==1 & df.ri$md==1)
o.losangeles.f.md <- df.ri$Matched[df.ri$female==1 & df.ri$losangeles==1 & df.ri$md==1]
#phd
n.losangeles.f.phd <- sum(df.ri$female==1 & df.ri$losangeles==1 & df.ri$phd==1)
o.losangeles.f.phd <- df.ri$Matched[df.ri$female==1 & df.ri$losangeles==1 & df.ri$phd==1]
#losangeles male
#control
n.losangeles.m.noedu <- sum(df.ri$female==0 & df.ri$losangeles==1 & df.ri$noedu==1)
o.losangeles.m.noedu <- df.ri$Matched[df.ri$female==0 & df.ri$losangeles==1 & df.ri$noedu==1]
#bs
n.losangeles.m.bs <- sum(df.ri$female==0 & df.ri$losangeles==1 & df.ri$bs==1)
o.losangeles.m.bs <- df.ri$Matched[df.ri$female==0 & df.ri$losangeles==1 & df.ri$bs==1]
#md
n.losangeles.m.md <- sum(df.ri$female==0 & df.ri$losangeles==1 & df.ri$md==1)
o.losangeles.m.md <- df.ri$Matched[df.ri$female==0 & df.ri$losangeles==1 & df.ri$md==1]
#phd
n.losangeles.m.phd <- sum(df.ri$female==0 & df.ri$losangeles==1 & df.ri$phd==1)
o.losangeles.m.phd <- df.ri$Matched[df.ri$female==0 & df.ri$losangeles==1 & df.ri$phd==1]

#newyork, female
#control
n.newyork.f.noedu <- sum(df.ri$female==1 & df.ri$newyork==1 & df.ri$noedu==1)
o.newyork.f.noedu <- df.ri$Matched[df.ri$female==1 & df.ri$newyork==1 & df.ri$noedu==1]
#bs
n.newyork.f.bs <- sum(df.ri$female==1 & df.ri$newyork==1 & df.ri$bs==1)
o.newyork.f.bs <- df.ri$Matched[df.ri$female==1 & df.ri$newyork==1 & df.ri$bs==1]
#md
n.newyork.f.md <- sum(df.ri$female==1 & df.ri$newyork==1 & df.ri$md==1)
o.newyork.f.md <- df.ri$Matched[df.ri$female==1 & df.ri$newyork==1 & df.ri$md==1]
#phd
n.newyork.f.phd <- sum(df.ri$female==1 & df.ri$newyork==1 & df.ri$phd==1)
o.newyork.f.phd <- df.ri$Matched[df.ri$female==1 & df.ri$newyork==1 & df.ri$phd==1]
#male
#control
n.newyork.m.noedu <- sum(df.ri$female==0 & df.ri$newyork==1 & df.ri$noedu==1)
o.newyork.m.noedu <- df.ri$Matched[df.ri$female==0 & df.ri$newyork==1 & df.ri$noedu==1]
#bs
n.newyork.m.bs <- sum(df.ri$female==0 & df.ri$newyork==1 & df.ri$bs==1)
o.newyork.m.bs <- df.ri$Matched[df.ri$female==0 & df.ri$newyork==1 & df.ri$bs==1]
#md
n.newyork.m.md <- sum(df.ri$female==0 & df.ri$newyork==1 & df.ri$md==1)
o.newyork.m.md <- df.ri$Matched[df.ri$female==0 & df.ri$newyork==1 & df.ri$md==1]
#phd
n.newyork.m.phd <- sum(df.ri$female==0 & df.ri$newyork==1 & df.ri$phd==1)
o.newyork.m.phd <- df.ri$Matched[df.ri$female==0 & df.ri$newyork==1 & df.ri$phd==1]

#philadelphia, female
#control
n.philadelphia.f.noedu <- sum(df.ri$female==1 & df.ri$philadelphia==1 & df.ri$noedu==1)
o.philadelphia.f.noedu <- df.ri$Matched[df.ri$female==1 & df.ri$philadelphia==1 & df.ri$noedu==1]
#bs
n.philadelphia.f.bs <- sum(df.ri$female==1 & df.ri$philadelphia==1 & df.ri$bs==1)
o.philadelphia.f.bs <- df.ri$Matched[df.ri$female==1 & df.ri$philadelphia==1 & df.ri$bs==1]
#md
n.philadelphia.f.md <- sum(df.ri$female==1 & df.ri$philadelphia==1 & df.ri$md==1)
o.philadelphia.f.md <- df.ri$Matched[df.ri$female==1 & df.ri$philadelphia==1 & df.ri$md==1]
#phd
n.philadelphia.f.phd <- sum(df.ri$female==1 & df.ri$philadelphia==1 & df.ri$phd==1)
o.philadelphia.f.phd <- df.ri$Matched[df.ri$female==1 & df.ri$philadelphia==1 & df.ri$phd==1]
#male
#control
n.philadelphia.m.noedu <- sum(df.ri$female==0 & df.ri$philadelphia==1 & df.ri$noedu==1)
o.philadelphia.m.noedu <- df.ri$Matched[df.ri$female==0 & df.ri$philadelphia==1 & df.ri$noedu==1]
#bs
n.philadelphia.m.bs <- sum(df.ri$female==0 & df.ri$philadelphia==1 & df.ri$bs==1)
o.philadelphia.m.bs <- df.ri$Matched[df.ri$female==0 & df.ri$philadelphia==1 & df.ri$bs==1]
#md
n.philadelphia.m.md <- sum(df.ri$female==0 & df.ri$philadelphia==1 & df.ri$md==1)
o.philadelphia.m.md <- df.ri$Matched[df.ri$female==0 & df.ri$philadelphia==1 & df.ri$md==1]
#phd
n.philadelphia.m.phd <- sum(df.ri$female==0 & df.ri$philadelphia==1 & df.ri$phd==1)
o.philadelphia.m.phd <- df.ri$Matched[df.ri$female==0 & df.ri$philadelphia==1 & df.ri$phd==1]

#phoenix, female
#control
n.phoenix.f.noedu <- sum(df.ri$female==1 & df.ri$phoenix==1 & df.ri$noedu==1)
o.phoenix.f.noedu <- df.ri$Matched[df.ri$female==1 & df.ri$phoenix==1 & df.ri$noedu==1]
#bs
n.phoenix.f.bs <- sum(df.ri$female==1 & df.ri$phoenix==1 & df.ri$bs==1)
o.phoenix.f.bs <- df.ri$Matched[df.ri$female==1 & df.ri$phoenix==1 & df.ri$bs==1]
#md
n.phoenix.f.md <- sum(df.ri$female==1 & df.ri$phoenix==1 & df.ri$md==1)
o.phoenix.f.md <- df.ri$Matched[df.ri$female==1 & df.ri$phoenix==1 & df.ri$md==1]
#phd
n.phoenix.f.phd <- sum(df.ri$female==1 & df.ri$phoenix==1 & df.ri$phd==1)
o.phoenix.f.phd <- df.ri$Matched[df.ri$female==1 & df.ri$phoenix==1 & df.ri$phd==1]
#male
#control
n.phoenix.m.noedu <- sum(df.ri$female==0 & df.ri$phoenix==1 & df.ri$noedu==1)
o.phoenix.m.noedu <- df.ri$Matched[df.ri$female==0 & df.ri$phoenix==1 & df.ri$noedu==1]
#bs
n.phoenix.m.bs <- sum(df.ri$female==0 & df.ri$phoenix==1 & df.ri$bs==1)
o.phoenix.m.bs <- df.ri$Matched[df.ri$female==0 & df.ri$phoenix==1 & df.ri$bs==1]
#md
n.phoenix.m.md <- sum(df.ri$female==0 & df.ri$phoenix==1 & df.ri$md==1)
o.phoenix.m.md <- df.ri$Matched[df.ri$female==0 & df.ri$phoenix==1 & df.ri$md==1]
#phd
n.phoenix.m.phd <- sum(df.ri$female==0 & df.ri$phoenix==1 & df.ri$phd==1)
o.phoenix.m.phd <- df.ri$Matched[df.ri$female==0 & df.ri$phoenix==1 & df.ri$phd==1]

#sanantonio, female
#control
n.sanantonio.f.noedu <- sum(df.ri$female==1 & df.ri$sanantonio==1 & df.ri$noedu==1)
o.sanantonio.f.noedu <- df.ri$Matched[df.ri$female==1 & df.ri$sanantonio==1 & df.ri$noedu==1]
#bs
n.sanantonio.f.bs <- sum(df.ri$female==1 & df.ri$sanantonio==1 & df.ri$bs==1)
o.sanantonio.f.bs <- df.ri$Matched[df.ri$female==1 & df.ri$sanantonio==1 & df.ri$bs==1]
#md
n.sanantonio.f.md <- sum(df.ri$female==1 & df.ri$sanantonio==1 & df.ri$md==1)
o.sanantonio.f.md <- df.ri$Matched[df.ri$female==1 & df.ri$sanantonio==1 & df.ri$md==1]
#phd
n.sanantonio.f.phd <- sum(df.ri$female==1 & df.ri$sanantonio==1 & df.ri$phd==1)
o.sanantonio.f.phd <- df.ri$Matched[df.ri$female==1 & df.ri$sanantonio==1 & df.ri$phd==1]
#male
#control
n.sanantonio.m.noedu <- sum(df.ri$female==0 & df.ri$sanantonio==1 & df.ri$noedu==1)
o.sanantonio.m.noedu <- df.ri$Matched[df.ri$female==0 & df.ri$sanantonio==1 & df.ri$noedu==1]
#bs
n.sanantonio.m.bs <- sum(df.ri$female==0 & df.ri$sanantonio==1 & df.ri$bs==1)
o.sanantonio.m.bs <- df.ri$Matched[df.ri$female==0 & df.ri$sanantonio==1 & df.ri$bs==1]
#md
n.sanantonio.m.md <- sum(df.ri$female==0 & df.ri$sanantonio==1 & df.ri$md==1)
o.sanantonio.m.md <- df.ri$Matched[df.ri$female==0 & df.ri$sanantonio==1 & df.ri$md==1]
#phd
n.sanantonio.m.phd <- sum(df.ri$female==0 & df.ri$sanantonio==1 & df.ri$phd==1)
o.sanantonio.m.phd <- df.ri$Matched[df.ri$female==0 & df.ri$sanantonio==1 & df.ri$phd==1]

#sandiego, female
#control
n.sandiego.f.noedu <- sum(df.ri$female==1 & df.ri$sandiego==1 & df.ri$noedu==1)
o.sandiego.f.noedu <- df.ri$Matched[df.ri$female==1 & df.ri$sandiego==1 & df.ri$noedu==1]
#bs
n.sandiego.f.bs <- sum(df.ri$female==1 & df.ri$sandiego==1 & df.ri$bs==1)
o.sandiego.f.bs <- df.ri$Matched[df.ri$female==1 & df.ri$sandiego==1 & df.ri$bs==1]
#md
n.sandiego.f.md <- sum(df.ri$female==1 & df.ri$sandiego==1 & df.ri$md==1)
o.sandiego.f.md <- df.ri$Matched[df.ri$female==1 & df.ri$sandiego==1 & df.ri$md==1]
#phd
n.sandiego.f.phd <- sum(df.ri$female==1 & df.ri$sandiego==1 & df.ri$phd==1)
o.sandiego.f.phd <- df.ri$Matched[df.ri$female==1 & df.ri$sandiego==1 & df.ri$phd==1]
#male
#control
n.sandiego.m.noedu <- sum(df.ri$female==0 & df.ri$sandiego==1 & df.ri$noedu==1)
o.sandiego.m.noedu <- df.ri$Matched[df.ri$female==0 & df.ri$sandiego==1 & df.ri$noedu==1]
#bs
n.sandiego.m.bs <- sum(df.ri$female==0 & df.ri$sandiego==1 & df.ri$bs==1)
o.sandiego.m.bs <- df.ri$Matched[df.ri$female==0 & df.ri$sandiego==1 & df.ri$bs==1]
#md
n.sandiego.m.md <- sum(df.ri$female==0 & df.ri$sandiego==1 & df.ri$md==1)
o.sandiego.m.md <- df.ri$Matched[df.ri$female==0 & df.ri$sandiego==1 & df.ri$md==1]
#phd
n.sandiego.m.phd <- sum(df.ri$female==0 & df.ri$sandiego==1 & df.ri$phd==1)
o.sandiego.m.phd <- df.ri$Matched[df.ri$female==0 & df.ri$sandiego==1 & df.ri$phd==1]
```

```{r echo=FALSE, message=FALSE}
bs.randomization <- function() c(randomize(n.chicago.f.noedu, n.chicago.f.bs), randomize(n.chicago.m.noedu, n.chicago.m.bs), randomize(n.houston.f.noedu, n.houston.f.bs), randomize(n.houston.m.noedu, n.houston.m.bs), randomize(n.losangeles.f.noedu, n.losangeles.f.bs), randomize(n.losangeles.m.noedu, n.losangeles.m.bs), randomize(n.newyork.f.noedu, n.newyork.f.bs), randomize(n.newyork.m.noedu, n.newyork.m.bs), randomize(n.philadelphia.f.noedu, n.philadelphia.f.bs), randomize(n.philadelphia.m.noedu, n.philadelphia.m.bs), randomize(n.phoenix.f.noedu, n.phoenix.f.bs), randomize(n.phoenix.m.noedu, n.phoenix.m.bs), randomize(n.sanantonio.f.noedu, n.sanantonio.f.bs), randomize(n.sanantonio.m.noedu, n.sanantonio.m.bs), randomize(n.sandiego.f.noedu, n.sandiego.f.bs), randomize(n.sandiego.m.noedu, n.sandiego.m.bs))

md.randomization <- function() c(randomize(n.chicago.f.noedu, n.chicago.f.md), randomize(n.chicago.m.noedu, n.chicago.m.md), randomize(n.houston.f.noedu, n.houston.f.md), randomize(n.houston.m.noedu, n.houston.m.md), randomize(n.losangeles.f.noedu, n.losangeles.f.md), randomize(n.losangeles.m.noedu, n.losangeles.m.md), randomize(n.newyork.f.noedu, n.newyork.f.md), randomize(n.newyork.m.noedu, n.newyork.m.md), randomize(n.philadelphia.f.noedu, n.philadelphia.f.md), randomize(n.philadelphia.m.noedu, n.philadelphia.m.md), randomize(n.phoenix.f.noedu, n.phoenix.f.md), randomize(n.phoenix.m.noedu, n.phoenix.m.md), randomize(n.sanantonio.f.noedu, n.sanantonio.f.md), randomize(n.sanantonio.m.noedu, n.sanantonio.m.md), randomize(n.sandiego.f.noedu, n.sandiego.f.md), randomize(n.sandiego.m.noedu, n.sandiego.m.md))

phd.randomization <- function() c(randomize(n.chicago.f.noedu, n.chicago.f.phd), randomize(n.chicago.m.noedu, n.chicago.m.phd), randomize(n.houston.f.noedu, n.houston.f.phd), randomize(n.houston.m.noedu, n.houston.m.phd), randomize(n.losangeles.f.noedu, n.losangeles.f.phd), randomize(n.losangeles.m.noedu, n.losangeles.m.phd), randomize(n.newyork.f.noedu, n.newyork.f.phd), randomize(n.newyork.m.noedu, n.newyork.m.phd), randomize(n.philadelphia.f.noedu, n.philadelphia.f.phd), randomize(n.philadelphia.m.noedu, n.philadelphia.m.phd), randomize(n.phoenix.f.noedu, n.phoenix.f.phd), randomize(n.phoenix.m.noedu, n.phoenix.m.phd), randomize(n.sanantonio.f.noedu, n.sanantonio.f.phd), randomize(n.sanantonio.m.noedu, n.sanantonio.m.phd), randomize(n.sandiego.f.noedu, n.sandiego.f.phd), randomize(n.sandiego.m.noedu, n.sandiego.m.phd))

combined.bs.outcomes <- c(o.chicago.f.noedu, o.chicago.f.bs, o.chicago.m.noedu, o.chicago.m.bs, o.houston.f.noedu, o.houston.f.bs, o.houston.m.noedu, o.houston.m.bs, o.losangeles.f.noedu, o.losangeles.f.bs, o.losangeles.m.noedu, o.losangeles.m.bs, o.newyork.f.noedu, o.newyork.f.bs, o.newyork.m.noedu, o.newyork.m.bs, o.philadelphia.f.noedu, o.philadelphia.f.bs, o.philadelphia.m.noedu, o.philadelphia.m.bs, o.phoenix.f.noedu, o.phoenix.f.bs, o.phoenix.m.noedu, o.phoenix.m.bs, o.sanantonio.f.noedu, o.sanantonio.f.bs, o.sanantonio.m.noedu, o.sanantonio.m.bs, o.sandiego.f.noedu, o.sandiego.f.bs, o.sandiego.m.noedu, o.sandiego.m.bs)

combined.md.outcomes <- c(o.chicago.f.noedu, o.chicago.f.md, o.chicago.m.noedu, o.chicago.m.md, o.houston.f.noedu, o.houston.f.md, o.houston.m.noedu, o.houston.m.md, o.losangeles.f.noedu, o.losangeles.f.md, o.losangeles.m.noedu, o.losangeles.m.md, o.newyork.f.noedu, o.newyork.f.md, o.newyork.m.noedu, o.newyork.m.md, o.philadelphia.f.noedu, o.philadelphia.f.md, o.philadelphia.m.noedu, o.philadelphia.m.md, o.phoenix.f.noedu, o.phoenix.f.md, o.phoenix.m.noedu, o.phoenix.m.md, o.sanantonio.f.noedu, o.sanantonio.f.md, o.sanantonio.m.noedu, o.sanantonio.m.md, o.sandiego.f.noedu, o.sandiego.f.md, o.sandiego.m.noedu, o.sandiego.m.md)

combined.phd.outcomes <- c(o.chicago.f.noedu, o.chicago.f.phd, o.chicago.m.noedu, o.chicago.m.phd, o.houston.f.noedu, o.houston.f.phd, o.houston.m.noedu, o.houston.m.phd, o.losangeles.f.noedu, o.losangeles.f.phd, o.losangeles.m.noedu, o.losangeles.m.phd, o.newyork.f.noedu, o.newyork.f.phd, o.newyork.m.noedu, o.newyork.m.phd, o.philadelphia.f.noedu, o.philadelphia.f.phd, o.philadelphia.m.noedu, o.philadelphia.m.phd, o.phoenix.f.noedu, o.phoenix.f.phd, o.phoenix.m.noedu, o.phoenix.m.phd, o.sanantonio.f.noedu, o.sanantonio.f.phd, o.sanantonio.m.noedu, o.sanantonio.m.phd, o.sandiego.f.noedu, o.sandiego.f.phd, o.sandiego.m.noedu, o.sandiego.m.phd)
```

Figures XXX-XXX show the distribution of the ATE (for each treatment) under the sharp null hypothesis, with a vertical line indicating the actual ATE estimate observed in the experiment.  The percentage of ATEs from simulation that are at least as extreme as the observed ATE is the p-value under randomization inference.

```{r echo=FALSE, message=FALSE}
distribution.under.sharp.null.bs <- replicate(10000, est.ate(combined.bs.outcomes, bs.randomization()))
bs.ate <- mean(df.ri$Matched[df.ri$bs==1]) - mean(df.ri$Matched[df.ri$noedu==1])
#bs.ate
#plot(density(distribution.under.sharp.null.bs), col="red", main="ATE Distribution Under the Sharp Null (BS)", xlab="ATE")
#abline(v=bs.ate)
bs.pvalue <- mean(bs.ate > distribution.under.sharp.null.bs)
```

```{r echo=FALSE, message=FALSE}
distribution.under.sharp.null.md <- replicate(10000, est.ate(combined.md.outcomes, md.randomization()))
md.ate <- mean(df.ri$Matched[df.ri$md==1]) - mean(df.ri$Matched[df.ri$noedu==1])
#md.ate
#plot(density(distribution.under.sharp.null.md), col="red", main="ATE Distribution Under the Sharp Null (MD)", xlab="ATE")
#abline(v=md.ate)
md.pvalue <- mean(md.ate < distribution.under.sharp.null.md)
```

Figure XXX shows the distribution of ATE of the MD treatment under the sharp null hypothesis

```{r echo=FALSE, message=FALSE}
distribution.under.sharp.null.phd <- replicate(10000, est.ate(combined.phd.outcomes, phd.randomization()))
phd.ate <- mean(df.ri$Matched[df.ri$phd==1]) - mean(df.ri$Matched[df.ri$noedu==1])
#phd.ate
#plot(density(distribution.under.sharp.null.phd), col="red", main="ATE Distribution Under the Sharp Null (PhD)", xlab="ATE")
#abline(v=phd.ate)
phd.pvalue <- mean(phd.ate < distribution.under.sharp.null.phd)
```

```{r echo=FALSE, message=FALSE, fig.width=11, fig.height=4}
par(mfrow = c(1,3))
plot(density(distribution.under.sharp.null.bs), col="red", main="ATE Distribution Under the Sharp Null (BS)", xlab="ATE")
abline(v=bs.ate)
plot(density(distribution.under.sharp.null.md), col="red", main="ATE Distribution Under the Sharp Null (MD)", xlab="ATE")
abline(v=md.ate)
plot(density(distribution.under.sharp.null.phd), col="red", main="ATE Distribution Under the Sharp Null (PhD)", xlab="ATE")
abline(v=phd.ate)
```

For the BS treatment, randomization inference yields a p-value of $`r bs.pvalue`$, which is not significant.  The p-value for the PhD treatment is again not significant under randomization inference ($`r phd.pvalue`$).  However, randomization inference shows a significant p-value of $`r md.pvalue`$ for the MD treatment, which provides further confirmation of the results of our analysis.

\pagebreak
## Conclusion

Our results indicate that females with an MD presented in their dating profile, receive a statistically significant increase in match rate of approximately 6.4% over females without an education level presented.  Further, our study found that indicating a bachelor's degree or a PhD had no statistically significant impact on female match rate.  These results are interesting as they contradict previous research that suggests males are less influenced by success factors in a partner than their female counterparts.

Despite these positive results, there are many changes that we would incorporate in further studies in this field.  Tactically, we would put an emphasis on fully capturing all covariates in a suitor's profile.  While this is not currently possible to automate, this could be performed manually.  The study could also be improved by running the research in the target markets to remove any suspicion caused by test subjects being alerted that our factitious user was hundreds or thousands of miles away.  Additionally, with increased technical resources, we would be interested in re-running this study for all profiles over the same time period to remove any variation caused by difference in weeks.  Additionally, further studies would be necessary to understand differences in the measuring period- i.e. would the results have changed if we allowed test subjects to match with our profiles over a two week period instead of only a one week period?  Finally, we would further broaden our treatment levels to include other levels of education such as master's degrees, JDs, PharmDs, etc.

To improve the generalizability of these results, we would further want to test this theory across different dating sites and services.  Further, the scope of the study would need to broaden to include international subjects, subjects in rural and suburban locations, and incorporate demographic information regarding race, religion, and income.  Further, by testing on other platforms, we would be interested to see if similar results are obtained gay and lesbian couples.



\pagebreak
## Works Consulted

"FAQ: How Do I Interpret Odds Ratios in Logistic Regression?" IDRE Stats, stats.idre.ucla.edu/other/mult-pkg/faq/general/faq-how-do-i-interpret-odds-ratios-in-logistic-regression/.

"Linear vs. Logistic Probability Models: Which Is Better, and When?" Statistical Horizons, statisticalhorizons.com/linear-vs-logistic.